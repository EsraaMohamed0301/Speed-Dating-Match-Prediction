{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSZRM15PNRMI"
      },
      "source": [
        "# **Questions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEwrNEdO6pjI"
      },
      "source": [
        "**Why a simple linear regression model (without any activation function) is not good for classification task, compared to Perceptron/Logistic regression?**\n",
        "\n",
        "> * Regression problems are solved using linear regression, while classification problems are solved using logistic regression.\n",
        "* Linear regression provides a continuous output but Logistic regression provides discreet output.\n",
        "* Linear regression's goal is to determine the best-fitting line, but logistic regression goes one step farther and fits the line values to the sigmoid curve.\n",
        "* The method for calculating loss function in linear regression is the mean squared error whereas for logistic regression it is maximum likelihood estimation.\n",
        "* When new data points are added, the threshold value shifts in linear regression."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9EjtxvEjJgV"
      },
      "source": [
        "**What's a decision tree and how it is different to a logistic regression model?**\n",
        "> * **What's a decision tree?** \n",
        " * For categorization and prediction, the decision tree is the most powerful and widely used technique. A decision tree is a flowchart-like tree structure in which each internal node represents an attribute test, each branch reflects the test's result, and each leaf node (terminal node) stores a class label.\n",
        "* **how it is different to a logistic regression model?**\n",
        " * The Decision Tree is easier to understand. However, Logistic Regression is more difficult to interpret.\n",
        " * The Decision Tree's Decision Boundaries are The space is divided into smaller areas by bisection. However, Logistic Regression Decision Boundaries are Linear and have only one decision boundary.\n",
        " * The Decision Tree's Decision Making Ease is Decision-making is handled automatically. However, Logistic Regression Decision Making Ease is A decision threshold must be established.\n",
        " * Decision Tree is Prone to overfitting. but Logistic Regression isn't prone to overfitting.\n",
        " * Noise has a significant impact on the Decision Tree's robustness to noise. However, Logistic Regression's robustness to noise is robust.\n",
        " * Decision Tree Scalability It's possible to train it on a modest training set. Scalability of Logistic Regression, on the other hand, necessitates a large enough training set.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAMHH0MPoa2c"
      },
      "source": [
        "**What's the difference between grid search and random search?**\n",
        " > * We no longer give a clear set of possible values for each hyperparameter in random search, unlike grid search. To execute a randomised search, we establish a sampling distribution for each hyperparameter, but grid search estimates the performance for each combination.\n",
        "* Using random search, we can also control or limit the number of hyperparameter combinations used *(we can specify to train only a fixed number of models and terminate the tuning algorithm post that)*. Unlike grid search, in which every possible combination is evaluated\n",
        "\n",
        "\n",
        "\\\n",
        "\n",
        "> *  Grid search\n",
        "   * Try out every combination of the parameters\n",
        "   * Computationally expensive\n",
        "   * Global optimal (within the given range)\n",
        "   * Sklearn: model_selection.GridSearchCV\n",
        "* Random search\n",
        " * Try out a random subset \n",
        " * `good enough`\n",
        " * Local optimal (within the given range)\n",
        " * Efficient (less trials)\n",
        " * Sklearn: model_selection.RandomizedSearchCV\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKFmAW0BobJd"
      },
      "source": [
        "**What's the difference between bayesian search and random search?**\n",
        "> * Random search\n",
        "  * Try out a random subset \n",
        "  * good enough\n",
        "  * Local optimal (within the given range)\n",
        "  * random search are completely uninformed by past evaluations.\n",
        "  * Efficient (less trials)\n",
        "  * Sklearn: model_selection.RandomizedSearchCV\n",
        "* Bayesian Optimization\n",
        " * As an optimization problem\n",
        " * it use to pick the next set of hyperparameters which will improve the model performance. We iteratively repeat this process until we converge to an optimum.(Trial -> estimated error -> Bayesian model estimates the next \n",
        "parameter to try -> trial -> repeat..)\n",
        " *  Bayesian methods can find the best hyperparameters in lesser time (in fewer iterations) than random search.\n",
        " * pip install bayesian-optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOXXtMFxiyMP"
      },
      "source": [
        "# **Problem Formulation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VhHuObDLnsE"
      },
      "source": [
        "## Define the problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zu3a6xp2bf9L"
      },
      "source": [
        "* This notebook will look into if dating preferences, attribute ratings, and background information can be used to forecast whether a partner will match with their date.\n",
        "* The problem can be framed as a supervised, binary classification problem where the model predicts if a partner has accepted or rejected their date.\n",
        "* The dataset is highly unbalanced."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1FDf-taLwws"
      },
      "source": [
        "## What is the input?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsRBoadNh4um"
      },
      "source": [
        "All Dataset without the match columns (191 number of input features). \n",
        "  \n",
        "**The Dataset**:\n",
        "* Participants attended a dating event where they had a 4-minute date with every other participant of the opposite sex who attended the same event.\n",
        "* The participants decided to accept or reject their partner. If both the participant and partner matched, they received each other's contact information.\n",
        "* Participants rated their partners on six personal attributes: attractiveness, sincerity, intelligence, fun, ambition and shared interests.\n",
        "* Before and after the event, participants rated their preferences in the six attributes and gave themselves ratings.\n",
        "* Other information was collected about the participants' background and preferences. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wBLUiHhL00D"
      },
      "source": [
        "## What is the output?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0BS7qIgonx0"
      },
      "source": [
        "The participants decided to accept or reject their partner. If both the participant and partner matched.\n",
        "In the dataset, the match column is output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfCzc5IBL41M"
      },
      "source": [
        "## What data mining function is required?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsLx29Ogon57"
      },
      "source": [
        "In this case, it will be binary Classification that separates data points into different classes (accept or reject / 1 or 0) which If both the participant and partner matched."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aj3_r7c2L8Qy"
      },
      "source": [
        "## What could be the challenges?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbJlj74yooAs"
      },
      "source": [
        "* the datasets have multiplue missing values.\n",
        "* the datasets are highly unbalanced.\n",
        "* predict the match betweem the participant and partner is correct. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9e_kyFjMAKD"
      },
      "source": [
        "## What is the impact?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hLc4Dt1qBLt"
      },
      "source": [
        "When I create a new system and give it some Features, it can decide whether or not people are compatible with one another. without these individuals coming together."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnFzpJWjqBOj"
      },
      "source": [
        "## What is an ideal solution?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sAlF3TN1SZP"
      },
      "source": [
        "According to my subsequent attempts, Bayesian Search and XGBoost Classifier with Cross Validation is the best approach because it provides me the highest kaggle score.\n",
        "\n",
        "     In Kaggle \n",
        "        * Public score: 0.88872\n",
        "        * Private score: 0.89038\n",
        "\n",
        "\n",
        "\n",
        "XGBoost Classifier is designed to be highly efficient, flexible and portable.\n",
        "\n",
        "\n",
        "The Bayesian Search use of intelligence to pick the next set of hyperparameters which will improve the model performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTW_FVARqBRD"
      },
      "source": [
        "## What is the experimental protocol used and how was it carried out?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Read the data using the function \"read_csv\"\n",
        "* Cleaning the dataset by I'll check for null values, duplicated values, drop some features and handle them. \n",
        "* The data is unbalanced, so i will use StandardScaler to making data points generalized so that the distance between them will be lower.\n",
        "* I will split the data to use Holdout method is split the training dataset to training data and validation data using \"train_test_split\".\n",
        "* convert the categorical values to numerical values using \"OneHotEncoder\".\n",
        "* I use Cross validation for training the model well.\n",
        "* Determine the optimal values for a given model by using GridSearch, RandomSearch and BayesianSearch.\n",
        "* I use Xgboost, logistic regression and svm to fit the model.  \n"
      ],
      "metadata": {
        "id": "x3sKd5d3r2Ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What preprocessing steps are used?"
      ],
      "metadata": {
        "id": "_ktcYEuvrsOj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okBPzKVgqmo8"
      },
      "source": [
        "* Missing value imputation.\n",
        "* Dropping some of features.\n",
        "* Transform the data.\n",
        "* Feature selction.\n",
        "* Standard Scaler (to handle the unbalanced data).\n",
        "* Encoder the Features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMfMKg6l6tqR"
      },
      "source": [
        "# **Implementation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAApGZ3TNfBJ"
      },
      "source": [
        "##  **Importation libraries**\n",
        "\n",
        "I will install a package and import several libraries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMZx3FycNlRQ"
      },
      "source": [
        "NumPy I can be used to perform a wide variety of mathematical operations on arrays.\n",
        "\n",
        "Pandas is a Python library for data analysis.\n",
        "\n",
        "Matplotlib is a python library used for Data Visualization.\n",
        "\n",
        "Sklearn provides a selection of efficient tools for machine learning and statistical modeling ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clVQMtjOWAUA",
        "outputId": "2eddb34a-d976-484d-950c-51d73514d6df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-optimize in /usr/local/lib/python3.7/dist-packages (0.9.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.21.5)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.0.2)\n",
            "Requirement already satisfied: pyaml>=16.9 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (21.10.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyaml>=16.9->scikit-optimize) (3.13)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->scikit-optimize) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-optimize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1wkw5mNNbbI"
      },
      "outputs": [],
      "source": [
        "# For uploading and accessing the data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# for Data Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# # for making statistical graphics.\n",
        "import seaborn as sns\n",
        "\n",
        "# for Encode categorical features as a numeric values\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# for scaling the data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# for split data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# for selecting column by data types\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# for assemble several steps that can be cross-validated together while setting different hyperparameters\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# for completing missing values.\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "\n",
        "# SelectKBest use for Select features according to the k highest scores. mutual_info_classif utilize the mutual information.\n",
        "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
        "\n",
        "\n",
        "# import Random Forest Classifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# import XGBoost Classifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# import SVC Classifier\n",
        "from sklearn.svm import SVC\n",
        "# import Decision Tree Classifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "# import Logistic Regression Classifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "# select the best parameters from the listed hyperparameters.\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from skopt import BayesSearchCV\n",
        "\n",
        "\n",
        "# Provides train/test indices to split data into train/test sets\n",
        "from sklearn.model_selection import PredefinedSplit\n",
        "\n",
        "\n",
        "\n",
        "# import warnings to prevent show warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TR4B76GhNp4Z"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pn0twbaGKppZ"
      },
      "source": [
        "## **Read Data**\n",
        "\n",
        "I Will connect to the drive and load and read train and test files from there. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3J_cMUa4Ks1o"
      },
      "source": [
        "I'll use the read csv function to read the data. It may read any delimited text file and change the delimiter by using the sep option.\n",
        "\n",
        "I'm going to read the training and testing datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgBgyvgUzAbv",
        "outputId": "310282ca-8fce-4939-ea37-d31bd97c4a28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Connect to my drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_QEhC06bKsAP"
      },
      "outputs": [],
      "source": [
        "# reading the training dataset \n",
        "df_train = pd.read_csv('/content/drive/MyDrive/Data Mining/Compition 2/train.csv') \n",
        "# df_train = pd.read_csv('train.csv') \n",
        "# reading the testing dataset \n",
        "df_test = pd.read_csv('/content/drive/MyDrive/Data Mining/Compition 2/test.csv') \n",
        "# df_test = pd.read_csv('test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-Gb6H6cK_Uj",
        "outputId": "2a4282b3-c7df-4366-9dad-12059faa5216"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8cbbc0d4-67be-4074-9790-35660ac0199a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>idg</th>\n",
              "      <th>condtn</th>\n",
              "      <th>wave</th>\n",
              "      <th>round</th>\n",
              "      <th>position</th>\n",
              "      <th>positin1</th>\n",
              "      <th>order</th>\n",
              "      <th>partner</th>\n",
              "      <th>pid</th>\n",
              "      <th>...</th>\n",
              "      <th>sinc3_3</th>\n",
              "      <th>intel3_3</th>\n",
              "      <th>fun3_3</th>\n",
              "      <th>amb3_3</th>\n",
              "      <th>attr5_3</th>\n",
              "      <th>sinc5_3</th>\n",
              "      <th>intel5_3</th>\n",
              "      <th>fun5_3</th>\n",
              "      <th>amb5_3</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>14</td>\n",
              "      <td>18</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>14</td>\n",
              "      <td>12</td>\n",
              "      <td>372.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>63.0</td>\n",
              "      <td>...</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>10</td>\n",
              "      <td>8</td>\n",
              "      <td>8.0</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>331.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>38</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>20</td>\n",
              "      <td>18</td>\n",
              "      <td>13.0</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>200.0</td>\n",
              "      <td>...</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>2</td>\n",
              "      <td>14</td>\n",
              "      <td>20</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>20</td>\n",
              "      <td>17</td>\n",
              "      <td>357.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4828</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 192 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8cbbc0d4-67be-4074-9790-35660ac0199a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8cbbc0d4-67be-4074-9790-35660ac0199a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8cbbc0d4-67be-4074-9790-35660ac0199a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   gender  idg  condtn  wave  round  position  positin1  order  partner  \\\n",
              "0       0    3       2    14     18         2       2.0     14       12   \n",
              "1       1   14       1     3     10         2       NaN      8        8   \n",
              "2       1   14       1    13     10         8       8.0     10       10   \n",
              "3       1   38       2     9     20        18      13.0      6        7   \n",
              "4       1   24       2    14     20         6       6.0     20       17   \n",
              "\n",
              "     pid  ...  sinc3_3  intel3_3  fun3_3  amb3_3  attr5_3  sinc5_3  intel5_3  \\\n",
              "0  372.0  ...      NaN       NaN     NaN     NaN      NaN      NaN       NaN   \n",
              "1   63.0  ...      8.0       8.0     7.0     8.0      NaN      NaN       NaN   \n",
              "2  331.0  ...      NaN       NaN     NaN     NaN      NaN      NaN       NaN   \n",
              "3  200.0  ...      9.0       8.0     8.0     6.0      NaN      NaN       NaN   \n",
              "4  357.0  ...      NaN       NaN     NaN     NaN      NaN      NaN       NaN   \n",
              "\n",
              "   fun5_3  amb5_3    id  \n",
              "0     NaN     NaN  2583  \n",
              "1     NaN     NaN  6830  \n",
              "2     NaN     NaN  4840  \n",
              "3     NaN     NaN  5508  \n",
              "4     NaN     NaN  4828  \n",
              "\n",
              "[5 rows x 192 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "#show heading of columns in trainig data\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LC9QX7o9pIDq"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wzvMLorLCh5",
        "outputId": "ed998278-f016-420d-d502-8eed8f9e0262"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1ed8d5a8-8c64-455d-bef1-17084cc8ac7a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>idg</th>\n",
              "      <th>condtn</th>\n",
              "      <th>wave</th>\n",
              "      <th>round</th>\n",
              "      <th>position</th>\n",
              "      <th>positin1</th>\n",
              "      <th>order</th>\n",
              "      <th>partner</th>\n",
              "      <th>pid</th>\n",
              "      <th>...</th>\n",
              "      <th>sinc3_3</th>\n",
              "      <th>intel3_3</th>\n",
              "      <th>fun3_3</th>\n",
              "      <th>amb3_3</th>\n",
              "      <th>attr5_3</th>\n",
              "      <th>sinc5_3</th>\n",
              "      <th>intel5_3</th>\n",
              "      <th>fun5_3</th>\n",
              "      <th>amb5_3</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>16</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>52.0</td>\n",
              "      <td>...</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>33</td>\n",
              "      <td>2</td>\n",
              "      <td>14</td>\n",
              "      <td>18</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>368.0</td>\n",
              "      <td>...</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6539</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>20</td>\n",
              "      <td>10</td>\n",
              "      <td>16.0</td>\n",
              "      <td>15</td>\n",
              "      <td>19</td>\n",
              "      <td>212.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>26</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>19</td>\n",
              "      <td>15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "      <td>30.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>29</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>16</td>\n",
              "      <td>7</td>\n",
              "      <td>7.0</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "      <td>162.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1052</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 191 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1ed8d5a8-8c64-455d-bef1-17084cc8ac7a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1ed8d5a8-8c64-455d-bef1-17084cc8ac7a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1ed8d5a8-8c64-455d-bef1-17084cc8ac7a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   gender  idg  condtn  wave  round  position  positin1  order  partner  \\\n",
              "0       0    5       2     2     16         3       NaN     13       13   \n",
              "1       0   33       2    14     18         6       6.0      4        8   \n",
              "2       1    6       2     9     20        10      16.0     15       19   \n",
              "3       1   26       2     2     19        15       NaN      8       10   \n",
              "4       0   29       2     7     16         7       7.0     10        5   \n",
              "\n",
              "     pid  ...  sinc3_3  intel3_3  fun3_3  amb3_3  attr5_3  sinc5_3  intel5_3  \\\n",
              "0   52.0  ...      7.0       8.0     6.0     8.0      NaN      NaN       NaN   \n",
              "1  368.0  ...      8.0       7.0     7.0     8.0      6.0      7.0       6.0   \n",
              "2  212.0  ...      NaN       NaN     NaN     NaN      NaN      NaN       NaN   \n",
              "3   30.0  ...      NaN       NaN     NaN     NaN      NaN      NaN       NaN   \n",
              "4  162.0  ...      NaN       NaN     NaN     NaN      NaN      NaN       NaN   \n",
              "\n",
              "   fun5_3  amb5_3    id  \n",
              "0     NaN     NaN   934  \n",
              "1     5.0     5.0  6539  \n",
              "2     NaN     NaN  6757  \n",
              "3     NaN     NaN  2275  \n",
              "4     NaN     NaN  1052  \n",
              "\n",
              "[5 rows x 191 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "#show heading of columns in testing data\n",
        "df_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoOR0uYzLFkJ",
        "outputId": "6f6860e0-87a9-4fbd-e6d6-f9a1b5bf0830"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape to traing :  (5909, 192)\n",
            "Shape to testing :  (2469, 191)\n"
          ]
        }
      ],
      "source": [
        "# show the training data shape\n",
        "print('Shape to traing : ', df_train.shape)\n",
        "# show the testing data shape\n",
        "print('Shape to testing : ', df_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAOz-ptUNEQI"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZ99GSdl63X1"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GSnNbXL4u4y"
      },
      "source": [
        "## **Functions**\n",
        "\n",
        "I'll do functions because I'll be using them a lot and don't want to repeat the code. such as plot the data, create pipline and set multiple classifiers and fit them, predict the testing set and record the probability of prediction in csv file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SrTGpbAy41pR"
      },
      "outputs": [],
      "source": [
        "# Make Funiction for display data to can anyone understand the data \n",
        "def plot_distribution(data, bins, title, xlabel, ylabel):\n",
        "  # plots a univariate distribution of observations.\n",
        "  ax = sns.distplot(\n",
        "      data,\n",
        "      bins=bins,\n",
        "      hist_kws={\n",
        "          \"linewidth\": 1,\n",
        "          'edgecolor': 'black',\n",
        "          'alpha': 1.0\n",
        "          },\n",
        "      kde=False\n",
        "  )\n",
        "  # set the title name to the plot\n",
        "  ax.set_title(title)\n",
        "  # set the label to x in the plot\n",
        "  ax.set_xlabel(xlabel)\n",
        "  # set the label to y in the plot\n",
        "  ax.set_ylabel(ylabel);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H89Qxb9nbva0"
      },
      "outputs": [],
      "source": [
        "# Make a Function to Pipeline preprocessor, selector and my_classifier\n",
        "# combine the preprocessor with the model as a full tunable pipeline\n",
        "# we gave them a name so we can set their hyperparameters\n",
        "\n",
        "def create_fit_pipeline(my_classifier):\n",
        "  full_pipeline = Pipeline(\n",
        "      steps=[\n",
        "          ('preprocessor', preprocessor),\n",
        "          ('selector', SelectKBest(mutual_info_classif, k=5)),\n",
        "          ('my_classifier', my_classifier)\n",
        "      ]\n",
        "  )\n",
        "  # The pipeline object can be used like any sk-learn model and training it \n",
        "  full_pipeline = full_pipeline.fit(x_train, y_train)\n",
        "  return full_pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcNxYeCrfQWs"
      },
      "outputs": [],
      "source": [
        "# Make Funiction to prediction the pipeline\n",
        "def predict_pipeline(full_pipeline):\n",
        "  # prediction the df_test\n",
        "  y_pred = full_pipeline.predict(df_test)\n",
        "  # Show unique and count values\n",
        "  return pd.DataFrame(y_pred).value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4VgxFZ2hFByd"
      },
      "outputs": [],
      "source": [
        "# Make a Function for predict the testing data and save it in the csv file\n",
        "def predict_save_csv(search_model, classifier_name):\n",
        "  submission = pd.DataFrame()\n",
        "  submission['id'] = df_test.index\n",
        "  submission['match'] = search_model.predict_proba(df_test)[:,1]\n",
        "  file_name = 'sample_submission_walkthrough_' + classifier_name + '.csv'\n",
        "  submission.to_csv(file_name, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NSrOxhJEoSLL"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_UQW3rwSPZ9"
      },
      "source": [
        "## **Quick look at the data**\n",
        "\n",
        "To begin, I displayed the information from the training and testing data, changed the id to the index, dropped several features from the training and testing sets, and changed the data type of object in features to category. Change the data type of the object in features to float and replace the values in the income feature. check the null values, check the duplicate values, show the nunique values in the training and testing set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwCdafFx_Xiw"
      },
      "outputs": [],
      "source": [
        "#  Set the index to become the id column in Training and test data\n",
        "df_train.set_index('id', drop=True, inplace= True)\n",
        "df_test.set_index('id', drop=True, inplace= True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmPnW6V9_iXP",
        "outputId": "53c3646e-a6f2-48fc-da64-fd97eda64d0c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b2f1d1c5-84ba-47e2-a0fd-204e685338cb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>idg</th>\n",
              "      <th>condtn</th>\n",
              "      <th>wave</th>\n",
              "      <th>round</th>\n",
              "      <th>position</th>\n",
              "      <th>positin1</th>\n",
              "      <th>order</th>\n",
              "      <th>partner</th>\n",
              "      <th>pid</th>\n",
              "      <th>...</th>\n",
              "      <th>attr3_3</th>\n",
              "      <th>sinc3_3</th>\n",
              "      <th>intel3_3</th>\n",
              "      <th>fun3_3</th>\n",
              "      <th>amb3_3</th>\n",
              "      <th>attr5_3</th>\n",
              "      <th>sinc5_3</th>\n",
              "      <th>intel5_3</th>\n",
              "      <th>fun5_3</th>\n",
              "      <th>amb5_3</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2583</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>14</td>\n",
              "      <td>18</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>14</td>\n",
              "      <td>12</td>\n",
              "      <td>372.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6830</th>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>63.0</td>\n",
              "      <td>...</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4840</th>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>10</td>\n",
              "      <td>8</td>\n",
              "      <td>8.0</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>331.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5508</th>\n",
              "      <td>1</td>\n",
              "      <td>38</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>20</td>\n",
              "      <td>18</td>\n",
              "      <td>13.0</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>200.0</td>\n",
              "      <td>...</td>\n",
              "      <td>8.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4828</th>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>2</td>\n",
              "      <td>14</td>\n",
              "      <td>20</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>20</td>\n",
              "      <td>17</td>\n",
              "      <td>357.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3390</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>20</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>214.0</td>\n",
              "      <td>...</td>\n",
              "      <td>12.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4130</th>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>20</td>\n",
              "      <td>19</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>199.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1178</th>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "      <td>21</td>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3</td>\n",
              "      <td>18</td>\n",
              "      <td>290.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5016</th>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>16</td>\n",
              "      <td>6</td>\n",
              "      <td>14.0</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>151.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8149</th>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>21</td>\n",
              "      <td>22</td>\n",
              "      <td>7</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>542.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5909 rows × 191 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b2f1d1c5-84ba-47e2-a0fd-204e685338cb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b2f1d1c5-84ba-47e2-a0fd-204e685338cb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b2f1d1c5-84ba-47e2-a0fd-204e685338cb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      gender  idg  condtn  wave  round  position  positin1  order  partner  \\\n",
              "id                                                                           \n",
              "2583       0    3       2    14     18         2       2.0     14       12   \n",
              "6830       1   14       1     3     10         2       NaN      8        8   \n",
              "4840       1   14       1    13     10         8       8.0     10       10   \n",
              "5508       1   38       2     9     20        18      13.0      6        7   \n",
              "4828       1   24       2    14     20         6       6.0     20       17   \n",
              "...      ...  ...     ...   ...    ...       ...       ...    ...      ...   \n",
              "3390       0    1       2     9     20         2       2.0     18        1   \n",
              "4130       1   24       2     9     20        19      15.0      5        6   \n",
              "1178       0   13       2    11     21         5       5.0      3       18   \n",
              "5016       1   10       2     7     16         6      14.0      9       10   \n",
              "8149       0    7       2    21     22         7       7.0      2       12   \n",
              "\n",
              "        pid  ...  attr3_3  sinc3_3  intel3_3  fun3_3  amb3_3  attr5_3  \\\n",
              "id           ...                                                        \n",
              "2583  372.0  ...      NaN      NaN       NaN     NaN     NaN      NaN   \n",
              "6830   63.0  ...      6.0      8.0       8.0     7.0     8.0      NaN   \n",
              "4840  331.0  ...      NaN      NaN       NaN     NaN     NaN      NaN   \n",
              "5508  200.0  ...      8.0      9.0       8.0     8.0     6.0      NaN   \n",
              "4828  357.0  ...      NaN      NaN       NaN     NaN     NaN      NaN   \n",
              "...     ...  ...      ...      ...       ...     ...     ...      ...   \n",
              "3390  214.0  ...     12.0     12.0      12.0     9.0    12.0      NaN   \n",
              "4130  199.0  ...      NaN      NaN       NaN     NaN     NaN      NaN   \n",
              "1178  290.0  ...      NaN      NaN       NaN     NaN     NaN      NaN   \n",
              "5016  151.0  ...      NaN      NaN       NaN     NaN     NaN      NaN   \n",
              "8149  542.0  ...      NaN      NaN       NaN     NaN     NaN      NaN   \n",
              "\n",
              "      sinc5_3  intel5_3  fun5_3  amb5_3  \n",
              "id                                       \n",
              "2583      NaN       NaN     NaN     NaN  \n",
              "6830      NaN       NaN     NaN     NaN  \n",
              "4840      NaN       NaN     NaN     NaN  \n",
              "5508      NaN       NaN     NaN     NaN  \n",
              "4828      NaN       NaN     NaN     NaN  \n",
              "...       ...       ...     ...     ...  \n",
              "3390      NaN       NaN     NaN     NaN  \n",
              "4130      NaN       NaN     NaN     NaN  \n",
              "1178      NaN       NaN     NaN     NaN  \n",
              "5016      NaN       NaN     NaN     NaN  \n",
              "8149      NaN       NaN     NaN     NaN  \n",
              "\n",
              "[5909 rows x 191 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "# show the training data\n",
        "df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xafmnNkTeAu",
        "outputId": "0143cac8-fc32-4b6f-8d4d-1f2799012576"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7091a30e-27b6-4b81-a093-2dc0eb32be9e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>idg</th>\n",
              "      <th>condtn</th>\n",
              "      <th>wave</th>\n",
              "      <th>round</th>\n",
              "      <th>position</th>\n",
              "      <th>positin1</th>\n",
              "      <th>order</th>\n",
              "      <th>partner</th>\n",
              "      <th>pid</th>\n",
              "      <th>...</th>\n",
              "      <th>attr3_3</th>\n",
              "      <th>sinc3_3</th>\n",
              "      <th>intel3_3</th>\n",
              "      <th>fun3_3</th>\n",
              "      <th>amb3_3</th>\n",
              "      <th>attr5_3</th>\n",
              "      <th>sinc5_3</th>\n",
              "      <th>intel5_3</th>\n",
              "      <th>fun5_3</th>\n",
              "      <th>amb5_3</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>934</th>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>16</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>52.0</td>\n",
              "      <td>...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6539</th>\n",
              "      <td>0</td>\n",
              "      <td>33</td>\n",
              "      <td>2</td>\n",
              "      <td>14</td>\n",
              "      <td>18</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>368.0</td>\n",
              "      <td>...</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6757</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>20</td>\n",
              "      <td>10</td>\n",
              "      <td>16.0</td>\n",
              "      <td>15</td>\n",
              "      <td>19</td>\n",
              "      <td>212.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2275</th>\n",
              "      <td>1</td>\n",
              "      <td>26</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>19</td>\n",
              "      <td>15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "      <td>30.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1052</th>\n",
              "      <td>0</td>\n",
              "      <td>29</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>16</td>\n",
              "      <td>7</td>\n",
              "      <td>7.0</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "      <td>162.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7982</th>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "      <td>2</td>\n",
              "      <td>15</td>\n",
              "      <td>19</td>\n",
              "      <td>18</td>\n",
              "      <td>18.0</td>\n",
              "      <td>14</td>\n",
              "      <td>11</td>\n",
              "      <td>407.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7299</th>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>339.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1818</th>\n",
              "      <td>1</td>\n",
              "      <td>26</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>19</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15</td>\n",
              "      <td>3</td>\n",
              "      <td>23.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>937</th>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>20</td>\n",
              "      <td>11</td>\n",
              "      <td>11.0</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>215.0</td>\n",
              "      <td>...</td>\n",
              "      <td>9.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6691</th>\n",
              "      <td>1</td>\n",
              "      <td>38</td>\n",
              "      <td>2</td>\n",
              "      <td>21</td>\n",
              "      <td>22</td>\n",
              "      <td>22</td>\n",
              "      <td>7.0</td>\n",
              "      <td>16</td>\n",
              "      <td>5</td>\n",
              "      <td>513.0</td>\n",
              "      <td>...</td>\n",
              "      <td>7.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2469 rows × 190 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7091a30e-27b6-4b81-a093-2dc0eb32be9e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7091a30e-27b6-4b81-a093-2dc0eb32be9e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7091a30e-27b6-4b81-a093-2dc0eb32be9e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      gender  idg  condtn  wave  round  position  positin1  order  partner  \\\n",
              "id                                                                           \n",
              "934        0    5       2     2     16         3       NaN     13       13   \n",
              "6539       0   33       2    14     18         6       6.0      4        8   \n",
              "6757       1    6       2     9     20        10      16.0     15       19   \n",
              "2275       1   26       2     2     19        15       NaN      8       10   \n",
              "1052       0   29       2     7     16         7       7.0     10        5   \n",
              "...      ...  ...     ...   ...    ...       ...       ...    ...      ...   \n",
              "7982       0   23       2    15     19        18      18.0     14       11   \n",
              "7299       0    5       1    13      9         4       4.0      4        8   \n",
              "1818       1   26       2     2     19         3       NaN     15        3   \n",
              "937        0   19       2     9     20        11      11.0      9        2   \n",
              "6691       1   38       2    21     22        22       7.0     16        5   \n",
              "\n",
              "        pid  ...  attr3_3  sinc3_3  intel3_3  fun3_3  amb3_3  attr5_3  \\\n",
              "id           ...                                                        \n",
              "934    52.0  ...      5.0      7.0       8.0     6.0     8.0      NaN   \n",
              "6539  368.0  ...      6.0      8.0       7.0     7.0     8.0      6.0   \n",
              "6757  212.0  ...      NaN      NaN       NaN     NaN     NaN      NaN   \n",
              "2275   30.0  ...      NaN      NaN       NaN     NaN     NaN      NaN   \n",
              "1052  162.0  ...      NaN      NaN       NaN     NaN     NaN      NaN   \n",
              "...     ...  ...      ...      ...       ...     ...     ...      ...   \n",
              "7982  407.0  ...      NaN      NaN       NaN     NaN     NaN      NaN   \n",
              "7299  339.0  ...      NaN      NaN       NaN     NaN     NaN      NaN   \n",
              "1818   23.0  ...      NaN      NaN       NaN     NaN     NaN      NaN   \n",
              "937   215.0  ...      9.0      7.0      12.0    12.0     9.0      NaN   \n",
              "6691  513.0  ...      7.0      9.0       8.0     7.0     8.0      5.0   \n",
              "\n",
              "      sinc5_3  intel5_3  fun5_3  amb5_3  \n",
              "id                                       \n",
              "934       NaN       NaN     NaN     NaN  \n",
              "6539      7.0       6.0     5.0     5.0  \n",
              "6757      NaN       NaN     NaN     NaN  \n",
              "2275      NaN       NaN     NaN     NaN  \n",
              "1052      NaN       NaN     NaN     NaN  \n",
              "...       ...       ...     ...     ...  \n",
              "7982      NaN       NaN     NaN     NaN  \n",
              "7299      NaN       NaN     NaN     NaN  \n",
              "1818      NaN       NaN     NaN     NaN  \n",
              "937       NaN       NaN     NaN     NaN  \n",
              "6691      8.0       8.0     6.0     8.0  \n",
              "\n",
              "[2469 rows x 190 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "# show the testing data\n",
        "df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FglBqEPJ_jRf"
      },
      "outputs": [],
      "source": [
        "# Drop some columns in training and testing data\n",
        "df_train = df_train.drop(['idg', 'pid', 'zipcode'], axis=1)\n",
        "df_test = df_test.drop(['idg', 'pid', 'zipcode'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0b2w1Dfz77nw",
        "outputId": "6cae366a-d0fd-4dd5-c7ca-654371360430"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 5909 entries, 2583 to 8149\n",
            "Columns: 188 entries, gender to amb5_3\n",
            "dtypes: float64(172), int64(9), object(7)\n",
            "memory usage: 8.5+ MB\n"
          ]
        }
      ],
      "source": [
        "#show information about training data\n",
        "df_train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GU5fEQ677rA",
        "outputId": "1ea5f9bb-74e7-4398-b6da-ca6e10de0437"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 2469 entries, 934 to 6691\n",
            "Columns: 187 entries, gender to amb5_3\n",
            "dtypes: float64(172), int64(8), object(7)\n",
            "memory usage: 3.5+ MB\n"
          ]
        }
      ],
      "source": [
        "#show information about testing data\n",
        "df_test.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5BknoKS9OMqK"
      },
      "outputs": [],
      "source": [
        "# categorical encoding of field in training and testing data \n",
        "df_train.field = df_train.field.astype('category')\n",
        "df_test.field = df_test.field.astype('category')\n",
        "\n",
        "# categorical encoding of undergra in training and testing data \n",
        "df_train.undergra = df_train.undergra.astype('category')\n",
        "df_test.undergra = df_test.undergra.astype('category')\n",
        "\n",
        "# categorical encoding of mn_sat in training and testing data \n",
        "df_train.mn_sat = df_train.mn_sat.astype('category')\n",
        "df_test.mn_sat = df_test.mn_sat.astype('category')\n",
        "\n",
        "# categorical encoding of tuition in training and testing data \n",
        "df_train.tuition = df_train.tuition.astype('category')\n",
        "df_test.tuition = df_test.tuition.astype('category')\n",
        "\n",
        "# categorical encoding of from in training and testing data \n",
        "df_train['from'] = df_train['from'].astype('category')\n",
        "df_test['from'] = df_test['from'].astype('category')\n",
        "\n",
        "# categorical encoding of career in training and testing data \n",
        "df_train.career = df_train.career.astype('category')\n",
        "df_test.career = df_test.career.astype('category')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bn4kXNc77uA"
      },
      "outputs": [],
      "source": [
        "# convert the datatype of gender from int to category in training and testing data \n",
        "df_train.gender = df_train.gender.astype('category')\n",
        "df_test.gender = df_test.gender.astype('category')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EA3B0buxzl_Z",
        "outputId": "d2c8d261-9c2f-4e56-c900-864077a8d962"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id\n",
              "2583         NaN\n",
              "6830         NaN\n",
              "4840         NaN\n",
              "5508    45300.00\n",
              "4828    46138.00\n",
              "          ...   \n",
              "3390    65708.00\n",
              "4130         NaN\n",
              "1178    37881.00\n",
              "5016         NaN\n",
              "8149         NaN\n",
              "Name: income, Length: 5909, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "# remove , from values in Feature (income) in trainig and testing set\n",
        "df_train.income = df_train.income.str.replace(',', '')\n",
        "df_test.income = df_test.income.str.replace(',', '')\n",
        "df_train.income"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XqkDAMIvZiE",
        "outputId": "8e020efa-f9d5-464a-a3c1-61681b13ef79"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x720 with 6 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# passing dictionary to rc parameter\n",
        "plt.figure(figsize=(16,10))\n",
        "\n",
        "# for automatically adjusts subplot params\n",
        "plt.tight_layout(pad=5.0)\n",
        "\n",
        "# can exist a group of smaller axes within a single figure in the columns 1.\n",
        "plt.subplot(2,3,1)\n",
        "\n",
        "# for display the plots to attr_o in training set \n",
        "plot_distribution(\n",
        "    data=df_train['attr_o'],\n",
        "    bins=np.arange(0, 10, 0.5).tolist(),\n",
        "    title='Subject\\'s attractiveness rating',\n",
        "    xlabel='Attractiveness rating',\n",
        "    ylabel='Number of subjects'\n",
        ")\n",
        "\n",
        "# can exist a group of smaller axes within a single figure in the columns 2.\n",
        "plt.subplot(2,3,2)\n",
        "\n",
        "# for display the plots to sinc_o in training set \n",
        "plot_distribution(\n",
        "    data=df_train['sinc_o'],\n",
        "    bins=np.arange(0, 10, 0.5).tolist(),\n",
        "    title='Subject\\'s sincerity rating',\n",
        "    xlabel='Sincerity rating',\n",
        "    ylabel='Number of subjects'\n",
        ")\n",
        "# can exist a group of smaller axes within a single figure in the columns 3.\n",
        "plt.subplot(2,3,3)\n",
        "\n",
        "# for display the plots to intel_o in training set \n",
        "plot_distribution(\n",
        "    data=df_train['intel_o'],\n",
        "    bins=np.arange(0, 10, 0.5).tolist(),\n",
        "    title='Subject\\'s intelligence rating',\n",
        "    xlabel='Intelligence rating',\n",
        "    ylabel='Number of subjects'\n",
        ")\n",
        "# can exist a group of smaller axes within a single figure in the columns 1.\n",
        "plt.subplot(2,3,4)\n",
        "# for display the plots to fun_o in training set \n",
        "plot_distribution(\n",
        "    data=df_train['fun_o'],\n",
        "    bins=np.arange(0, 10, 0.5).tolist(),\n",
        "    title='Subject\\'s fun rating',\n",
        "    xlabel='Fun rating',\n",
        "    ylabel='Number of subjects'\n",
        ")\n",
        "# can exist a group of smaller axes within a single figure in the columns 2.\n",
        "plt.subplot(2,3,5)\n",
        "# for display the plots to amb_o in training set \n",
        "plot_distribution(\n",
        "    data=df_train['amb_o'],\n",
        "    bins=np.arange(0, 10, 0.5).tolist(),\n",
        "    title='Subject\\'s ambition rating',\n",
        "    xlabel='Ambition rating',\n",
        "    ylabel='Number of subjects'\n",
        ")\n",
        "# can exist a group of smaller axes within a single figure in the columns 3.\n",
        "plt.subplot(2,3,6)\n",
        "# for display the plots to shar_o in training set \n",
        "plot_distribution(\n",
        "    data=df_train['shar_o'],\n",
        "    bins=np.arange(0, 10, 0.5).tolist(),\n",
        "    title='Subject\\'s shared interest rating',\n",
        "    xlabel='Shared interest rating',\n",
        "    ylabel='Number of subjects'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ys5QNIaHyeni",
        "outputId": "98a513c7-7d11-4b21-f3ac-05de720d6e30"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id\n",
              "2583        NaN\n",
              "6830        NaN\n",
              "4840        NaN\n",
              "5508    45300.0\n",
              "4828    46138.0\n",
              "         ...   \n",
              "3390    65708.0\n",
              "4130        NaN\n",
              "1178    37881.0\n",
              "5016        NaN\n",
              "8149        NaN\n",
              "Name: income, Length: 5909, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "# convert the datatype of gender from int to object in training and testing data \n",
        "df_train.income = df_train.income.astype('float64')\n",
        "df_test.income = df_test.income.astype('float64')\n",
        "\n",
        "df_train.income"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBhGMSE61xlX"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6lJyVlX92x_",
        "outputId": "9034198e-90b4-462d-fbbe-90a5bfa97d4d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a3ccf451-5bbe-45e0-b8b5-bf74d4558749\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>condtn</th>\n",
              "      <th>wave</th>\n",
              "      <th>round</th>\n",
              "      <th>position</th>\n",
              "      <th>positin1</th>\n",
              "      <th>order</th>\n",
              "      <th>partner</th>\n",
              "      <th>match</th>\n",
              "      <th>int_corr</th>\n",
              "      <th>...</th>\n",
              "      <th>attr3_3</th>\n",
              "      <th>sinc3_3</th>\n",
              "      <th>intel3_3</th>\n",
              "      <th>fun3_3</th>\n",
              "      <th>amb3_3</th>\n",
              "      <th>attr5_3</th>\n",
              "      <th>sinc5_3</th>\n",
              "      <th>intel5_3</th>\n",
              "      <th>fun5_3</th>\n",
              "      <th>amb5_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5909.0</td>\n",
              "      <td>5909.000000</td>\n",
              "      <td>5909.000000</td>\n",
              "      <td>5909.000000</td>\n",
              "      <td>5909.000000</td>\n",
              "      <td>4591.000000</td>\n",
              "      <td>5909.00000</td>\n",
              "      <td>5909.000000</td>\n",
              "      <td>5909.000000</td>\n",
              "      <td>5800.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>2804.000000</td>\n",
              "      <td>2804.000000</td>\n",
              "      <td>2804.000000</td>\n",
              "      <td>2804.000000</td>\n",
              "      <td>2804.000000</td>\n",
              "      <td>1413.000000</td>\n",
              "      <td>1413.000000</td>\n",
              "      <td>1413.000000</td>\n",
              "      <td>1413.000000</td>\n",
              "      <td>1413.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>2986.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>NaN</td>\n",
              "      <td>1.824843</td>\n",
              "      <td>11.347436</td>\n",
              "      <td>16.850228</td>\n",
              "      <td>9.001523</td>\n",
              "      <td>9.254846</td>\n",
              "      <td>8.91166</td>\n",
              "      <td>8.962938</td>\n",
              "      <td>0.167203</td>\n",
              "      <td>0.195257</td>\n",
              "      <td>...</td>\n",
              "      <td>7.241797</td>\n",
              "      <td>8.105563</td>\n",
              "      <td>8.377318</td>\n",
              "      <td>7.644437</td>\n",
              "      <td>7.398716</td>\n",
              "      <td>6.799717</td>\n",
              "      <td>7.631989</td>\n",
              "      <td>7.944798</td>\n",
              "      <td>7.162774</td>\n",
              "      <td>7.092711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>NaN</td>\n",
              "      <td>0.380133</td>\n",
              "      <td>6.011495</td>\n",
              "      <td>4.389246</td>\n",
              "      <td>5.482368</td>\n",
              "      <td>5.611803</td>\n",
              "      <td>5.45710</td>\n",
              "      <td>5.500706</td>\n",
              "      <td>0.373188</td>\n",
              "      <td>0.304197</td>\n",
              "      <td>...</td>\n",
              "      <td>1.593787</td>\n",
              "      <td>1.601011</td>\n",
              "      <td>1.459013</td>\n",
              "      <td>1.757559</td>\n",
              "      <td>1.956924</td>\n",
              "      <td>1.535768</td>\n",
              "      <td>1.498024</td>\n",
              "      <td>1.320919</td>\n",
              "      <td>1.687431</td>\n",
              "      <td>1.713729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.830000</td>\n",
              "      <td>...</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.00000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.020000</td>\n",
              "      <td>...</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>6.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>8.00000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.210000</td>\n",
              "      <td>...</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>7.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>13.00000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.430000</td>\n",
              "      <td>...</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>NaN</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>22.00000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.910000</td>\n",
              "      <td>...</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11 rows × 188 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a3ccf451-5bbe-45e0-b8b5-bf74d4558749')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a3ccf451-5bbe-45e0-b8b5-bf74d4558749 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a3ccf451-5bbe-45e0-b8b5-bf74d4558749');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        gender       condtn         wave        round     position  \\\n",
              "count   5909.0  5909.000000  5909.000000  5909.000000  5909.000000   \n",
              "unique     2.0          NaN          NaN          NaN          NaN   \n",
              "top        1.0          NaN          NaN          NaN          NaN   \n",
              "freq    2986.0          NaN          NaN          NaN          NaN   \n",
              "mean       NaN     1.824843    11.347436    16.850228     9.001523   \n",
              "std        NaN     0.380133     6.011495     4.389246     5.482368   \n",
              "min        NaN     1.000000     1.000000     5.000000     1.000000   \n",
              "25%        NaN     2.000000     7.000000    14.000000     4.000000   \n",
              "50%        NaN     2.000000    11.000000    18.000000     8.000000   \n",
              "75%        NaN     2.000000    15.000000    20.000000    13.000000   \n",
              "max        NaN     2.000000    21.000000    22.000000    22.000000   \n",
              "\n",
              "           positin1       order      partner        match     int_corr  ...  \\\n",
              "count   4591.000000  5909.00000  5909.000000  5909.000000  5800.000000  ...   \n",
              "unique          NaN         NaN          NaN          NaN          NaN  ...   \n",
              "top             NaN         NaN          NaN          NaN          NaN  ...   \n",
              "freq            NaN         NaN          NaN          NaN          NaN  ...   \n",
              "mean       9.254846     8.91166     8.962938     0.167203     0.195257  ...   \n",
              "std        5.611803     5.45710     5.500706     0.373188     0.304197  ...   \n",
              "min        1.000000     1.00000     1.000000     0.000000    -0.830000  ...   \n",
              "25%        4.000000     4.00000     4.000000     0.000000    -0.020000  ...   \n",
              "50%        9.000000     8.00000     8.000000     0.000000     0.210000  ...   \n",
              "75%       14.000000    13.00000    13.000000     0.000000     0.430000  ...   \n",
              "max       22.000000    22.00000    22.000000     1.000000     0.910000  ...   \n",
              "\n",
              "            attr3_3      sinc3_3     intel3_3       fun3_3       amb3_3  \\\n",
              "count   2804.000000  2804.000000  2804.000000  2804.000000  2804.000000   \n",
              "unique          NaN          NaN          NaN          NaN          NaN   \n",
              "top             NaN          NaN          NaN          NaN          NaN   \n",
              "freq            NaN          NaN          NaN          NaN          NaN   \n",
              "mean       7.241797     8.105563     8.377318     7.644437     7.398716   \n",
              "std        1.593787     1.601011     1.459013     1.757559     1.956924   \n",
              "min        2.000000     2.000000     3.000000     2.000000     1.000000   \n",
              "25%        7.000000     7.000000     8.000000     7.000000     6.000000   \n",
              "50%        7.000000     8.000000     8.000000     8.000000     8.000000   \n",
              "75%        8.000000     9.000000     9.000000     9.000000     9.000000   \n",
              "max       12.000000    12.000000    12.000000    12.000000    12.000000   \n",
              "\n",
              "            attr5_3      sinc5_3     intel5_3       fun5_3       amb5_3  \n",
              "count   1413.000000  1413.000000  1413.000000  1413.000000  1413.000000  \n",
              "unique          NaN          NaN          NaN          NaN          NaN  \n",
              "top             NaN          NaN          NaN          NaN          NaN  \n",
              "freq            NaN          NaN          NaN          NaN          NaN  \n",
              "mean       6.799717     7.631989     7.944798     7.162774     7.092711  \n",
              "std        1.535768     1.498024     1.320919     1.687431     1.713729  \n",
              "min        2.000000     2.000000     4.000000     1.000000     1.000000  \n",
              "25%        6.000000     7.000000     7.000000     6.000000     6.000000  \n",
              "50%        7.000000     8.000000     8.000000     7.000000     7.000000  \n",
              "75%        8.000000     9.000000     9.000000     8.000000     8.000000  \n",
              "max       10.000000    10.000000    10.000000    10.000000    10.000000  \n",
              "\n",
              "[11 rows x 188 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "# show all statistics in training data\n",
        "df_train.describe(include='all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ie7O_OP97-u",
        "outputId": "bcfe90bb-00ed-4cf8-8e5e-94ecf497fc11"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-63f54894-816c-448d-b84f-daf2f8b76914\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>condtn</th>\n",
              "      <th>wave</th>\n",
              "      <th>round</th>\n",
              "      <th>position</th>\n",
              "      <th>positin1</th>\n",
              "      <th>order</th>\n",
              "      <th>partner</th>\n",
              "      <th>int_corr</th>\n",
              "      <th>samerace</th>\n",
              "      <th>...</th>\n",
              "      <th>attr3_3</th>\n",
              "      <th>sinc3_3</th>\n",
              "      <th>intel3_3</th>\n",
              "      <th>fun3_3</th>\n",
              "      <th>amb3_3</th>\n",
              "      <th>attr5_3</th>\n",
              "      <th>sinc5_3</th>\n",
              "      <th>intel5_3</th>\n",
              "      <th>fun5_3</th>\n",
              "      <th>amb5_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2469.0</td>\n",
              "      <td>2469.000000</td>\n",
              "      <td>2469.000000</td>\n",
              "      <td>2469.000000</td>\n",
              "      <td>2469.000000</td>\n",
              "      <td>1941.000000</td>\n",
              "      <td>2469.000000</td>\n",
              "      <td>2469.000000</td>\n",
              "      <td>2420.000000</td>\n",
              "      <td>2469.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1170.000000</td>\n",
              "      <td>1170.000000</td>\n",
              "      <td>1170.000000</td>\n",
              "      <td>1170.000000</td>\n",
              "      <td>1170.000000</td>\n",
              "      <td>603.000000</td>\n",
              "      <td>603.000000</td>\n",
              "      <td>603.000000</td>\n",
              "      <td>603.000000</td>\n",
              "      <td>603.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1261.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>NaN</td>\n",
              "      <td>1.838396</td>\n",
              "      <td>11.359255</td>\n",
              "      <td>16.924261</td>\n",
              "      <td>9.141353</td>\n",
              "      <td>9.392581</td>\n",
              "      <td>8.965978</td>\n",
              "      <td>8.965168</td>\n",
              "      <td>0.197814</td>\n",
              "      <td>0.394492</td>\n",
              "      <td>...</td>\n",
              "      <td>7.236752</td>\n",
              "      <td>8.064103</td>\n",
              "      <td>8.416239</td>\n",
              "      <td>7.693162</td>\n",
              "      <td>7.374359</td>\n",
              "      <td>6.834163</td>\n",
              "      <td>7.575456</td>\n",
              "      <td>7.903814</td>\n",
              "      <td>7.137645</td>\n",
              "      <td>6.945274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>NaN</td>\n",
              "      <td>0.368162</td>\n",
              "      <td>5.959627</td>\n",
              "      <td>4.284307</td>\n",
              "      <td>5.592006</td>\n",
              "      <td>5.740292</td>\n",
              "      <td>5.525290</td>\n",
              "      <td>5.469045</td>\n",
              "      <td>0.302013</td>\n",
              "      <td>0.488840</td>\n",
              "      <td>...</td>\n",
              "      <td>1.535277</td>\n",
              "      <td>1.632694</td>\n",
              "      <td>1.459546</td>\n",
              "      <td>1.713641</td>\n",
              "      <td>1.972877</td>\n",
              "      <td>1.439486</td>\n",
              "      <td>1.520249</td>\n",
              "      <td>1.387187</td>\n",
              "      <td>1.639208</td>\n",
              "      <td>1.724936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.830000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>-0.010000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>6.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.210000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>7.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>0.430000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>NaN</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>0.910000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11 rows × 187 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-63f54894-816c-448d-b84f-daf2f8b76914')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-63f54894-816c-448d-b84f-daf2f8b76914 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-63f54894-816c-448d-b84f-daf2f8b76914');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        gender       condtn         wave        round     position  \\\n",
              "count   2469.0  2469.000000  2469.000000  2469.000000  2469.000000   \n",
              "unique     2.0          NaN          NaN          NaN          NaN   \n",
              "top        0.0          NaN          NaN          NaN          NaN   \n",
              "freq    1261.0          NaN          NaN          NaN          NaN   \n",
              "mean       NaN     1.838396    11.359255    16.924261     9.141353   \n",
              "std        NaN     0.368162     5.959627     4.284307     5.592006   \n",
              "min        NaN     1.000000     1.000000     5.000000     1.000000   \n",
              "25%        NaN     2.000000     7.000000    14.000000     4.000000   \n",
              "50%        NaN     2.000000    11.000000    18.000000     8.000000   \n",
              "75%        NaN     2.000000    15.000000    20.000000    13.000000   \n",
              "max        NaN     2.000000    21.000000    22.000000    22.000000   \n",
              "\n",
              "           positin1        order      partner     int_corr     samerace  ...  \\\n",
              "count   1941.000000  2469.000000  2469.000000  2420.000000  2469.000000  ...   \n",
              "unique          NaN          NaN          NaN          NaN          NaN  ...   \n",
              "top             NaN          NaN          NaN          NaN          NaN  ...   \n",
              "freq            NaN          NaN          NaN          NaN          NaN  ...   \n",
              "mean       9.392581     8.965978     8.965168     0.197814     0.394492  ...   \n",
              "std        5.740292     5.525290     5.469045     0.302013     0.488840  ...   \n",
              "min        1.000000     1.000000     1.000000    -0.830000     0.000000  ...   \n",
              "25%        4.000000     4.000000     4.000000    -0.010000     0.000000  ...   \n",
              "50%        9.000000     8.000000     8.000000     0.210000     0.000000  ...   \n",
              "75%       14.000000    13.000000    13.000000     0.430000     1.000000  ...   \n",
              "max       22.000000    22.000000    22.000000     0.910000     1.000000  ...   \n",
              "\n",
              "            attr3_3      sinc3_3     intel3_3       fun3_3       amb3_3  \\\n",
              "count   1170.000000  1170.000000  1170.000000  1170.000000  1170.000000   \n",
              "unique          NaN          NaN          NaN          NaN          NaN   \n",
              "top             NaN          NaN          NaN          NaN          NaN   \n",
              "freq            NaN          NaN          NaN          NaN          NaN   \n",
              "mean       7.236752     8.064103     8.416239     7.693162     7.374359   \n",
              "std        1.535277     1.632694     1.459546     1.713641     1.972877   \n",
              "min        2.000000     2.000000     3.000000     2.000000     1.000000   \n",
              "25%        7.000000     7.000000     8.000000     7.000000     6.000000   \n",
              "50%        7.000000     8.000000     8.000000     8.000000     8.000000   \n",
              "75%        8.000000     9.000000     9.000000     9.000000     9.000000   \n",
              "max       12.000000    12.000000    12.000000    12.000000    12.000000   \n",
              "\n",
              "           attr5_3     sinc5_3    intel5_3      fun5_3      amb5_3  \n",
              "count   603.000000  603.000000  603.000000  603.000000  603.000000  \n",
              "unique         NaN         NaN         NaN         NaN         NaN  \n",
              "top            NaN         NaN         NaN         NaN         NaN  \n",
              "freq           NaN         NaN         NaN         NaN         NaN  \n",
              "mean      6.834163    7.575456    7.903814    7.137645    6.945274  \n",
              "std       1.439486    1.520249    1.387187    1.639208    1.724936  \n",
              "min       2.000000    2.000000    4.000000    1.000000    1.000000  \n",
              "25%       6.000000    7.000000    7.000000    6.000000    6.000000  \n",
              "50%       7.000000    8.000000    8.000000    7.000000    7.000000  \n",
              "75%       8.000000    9.000000    9.000000    8.000000    8.000000  \n",
              "max      10.000000   10.000000   10.000000   10.000000   10.000000  \n",
              "\n",
              "[11 rows x 187 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "# show all statistics in testing data\n",
        "df_test.describe(include='all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MI5b7TNU-Eo_",
        "outputId": "f6e68d96-5a57-401d-b25f-4975d393b47b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "# First, lets show sum of duplicate values (if any)\n",
        "df_train.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I11uVuUE-P6f",
        "outputId": "bc59e7aa-8d5e-4b0c-b05e-8c6feca021e1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "gender        2\n",
              "condtn        2\n",
              "match         2\n",
              "date_3        2\n",
              "samerace      2\n",
              "           ... \n",
              "undergra    241\n",
              "field       259\n",
              "income      261\n",
              "from        269\n",
              "career      367\n",
              "Length: 188, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "# show the count of all the unique values in the training data\n",
        "df_train.nunique().sort_values(ascending=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFg1busZ-bR_",
        "outputId": "dcc421f6-bd09-4827-df53-2b2d3d09750f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "gender        2\n",
              "condtn        2\n",
              "date_3        2\n",
              "samerace      2\n",
              "met_o         3\n",
              "           ... \n",
              "undergra    235\n",
              "income      253\n",
              "field       254\n",
              "from        265\n",
              "career      358\n",
              "Length: 187, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "# show the count of all the unique values in the testing data\n",
        "df_test.nunique().sort_values(ascending=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nG_HcVrR_Fh-"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MezsbxtF77lB",
        "outputId": "adde3401-d406-4045-fd4f-767390dda542"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "num_in_3    5449\n",
              "numdat_3    4849\n",
              "expnum      4627\n",
              "amb7_2      4519\n",
              "sinc7_2     4519\n",
              "            ... \n",
              "order          0\n",
              "position       0\n",
              "round          0\n",
              "wave           0\n",
              "gender         0\n",
              "Length: 188, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "# anything missing in training data? \n",
        "df_train.isnull().sum().sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "565FXBTs77wg",
        "outputId": "51a84464-4025-4952-c521-d44494e74cfb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "num_in_3    2261\n",
              "numdat_3    2033\n",
              "expnum      1951\n",
              "sinc7_2     1904\n",
              "amb7_2      1904\n",
              "            ... \n",
              "order          0\n",
              "position       0\n",
              "round          0\n",
              "wave           0\n",
              "gender         0\n",
              "Length: 187, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "# anything missing in testing data? \n",
        "df_test.isnull().sum().sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFciQeq_MjnQ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiDqqaiSUHl0"
      },
      "source": [
        "## **Split the data**\n",
        "Split the training and PredefinedSplit is created by splitting the training data to split cross-validator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2G6XyAA6AX9p"
      },
      "outputs": [],
      "source": [
        "# Spliting the traing data to x_train (the Features) and y_train (the Label)\n",
        "y_train = df_train['match'] # lower case for vector\n",
        "x_train = df_train.drop('match', axis=1) # upper case for matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmzhFJzFBQrX"
      },
      "outputs": [],
      "source": [
        "# # Split the traing data 80% for training and 20% for validation data\n",
        "# x_train, x_val, y_train, y_val = train_test_split(X, y, test_size= 0.2, shuffle=True, random_state= 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWUT7Kqy-NRo"
      },
      "outputs": [],
      "source": [
        "# Further split the original training set to a train and a validation set\n",
        "X_train2, X_val, y_train2, y_val = train_test_split(\n",
        "    x_train, y_train, train_size = 0.8, stratify = y_train, random_state = 42)\n",
        "\n",
        "# Create a list where train data indices are -1 and validation data indices are 0\n",
        "# X_train2 (new training set), X_train\n",
        "split_index = [-1 if x in X_train2.index else 0 for x in x_train.index]\n",
        "\n",
        "# Use the list to create PredefinedSplit\n",
        "pds = PredefinedSplit(test_fold = split_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FABO1ogiB_aw"
      },
      "source": [
        "## **A Tunable Pipeline**\n",
        "As a single tunable pipeline with hyper-parameters, we can combine preprocessing stages and model. Define a pipeline for transformer numeric and categorical feature. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmAIDAhdCD7d",
        "outputId": "6ab3baa9-bbdc-49ff-d4d9-2d437af55190"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numeric features: ['condtn', 'wave', 'round', 'position', 'positin1', 'order', 'partner', 'int_corr', 'samerace', 'age_o', 'race_o', 'pf_o_att', 'pf_o_sin', 'pf_o_int', 'pf_o_fun', 'pf_o_amb', 'pf_o_sha', 'attr_o', 'sinc_o', 'intel_o', 'fun_o', 'amb_o', 'shar_o', 'like_o', 'prob_o', 'met_o', 'age', 'field_cd', 'race', 'imprace', 'imprelig', 'income', 'goal', 'date', 'go_out', 'career_c', 'sports', 'tvsports', 'exercise', 'dining', 'museums', 'art', 'hiking', 'gaming', 'clubbing', 'reading', 'tv', 'theater', 'movies', 'concerts', 'music', 'shopping', 'yoga', 'exphappy', 'expnum', 'attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', 'amb1_1', 'shar1_1', 'attr4_1', 'sinc4_1', 'intel4_1', 'fun4_1', 'amb4_1', 'shar4_1', 'attr2_1', 'sinc2_1', 'intel2_1', 'fun2_1', 'amb2_1', 'shar2_1', 'attr3_1', 'sinc3_1', 'fun3_1', 'intel3_1', 'amb3_1', 'attr5_1', 'sinc5_1', 'intel5_1', 'fun5_1', 'amb5_1', 'attr', 'sinc', 'intel', 'fun', 'amb', 'shar', 'like', 'prob', 'met', 'match_es', 'attr1_s', 'sinc1_s', 'intel1_s', 'fun1_s', 'amb1_s', 'shar1_s', 'attr3_s', 'sinc3_s', 'intel3_s', 'fun3_s', 'amb3_s', 'satis_2', 'length', 'numdat_2', 'attr7_2', 'sinc7_2', 'intel7_2', 'fun7_2', 'amb7_2', 'shar7_2', 'attr1_2', 'sinc1_2', 'intel1_2', 'fun1_2', 'amb1_2', 'shar1_2', 'attr4_2', 'sinc4_2', 'intel4_2', 'fun4_2', 'amb4_2', 'shar4_2', 'attr2_2', 'sinc2_2', 'intel2_2', 'fun2_2', 'amb2_2', 'shar2_2', 'attr3_2', 'sinc3_2', 'intel3_2', 'fun3_2', 'amb3_2', 'attr5_2', 'sinc5_2', 'intel5_2', 'fun5_2', 'amb5_2', 'you_call', 'them_cal', 'date_3', 'numdat_3', 'num_in_3', 'attr1_3', 'sinc1_3', 'intel1_3', 'fun1_3', 'amb1_3', 'shar1_3', 'attr7_3', 'sinc7_3', 'intel7_3', 'fun7_3', 'amb7_3', 'shar7_3', 'attr4_3', 'sinc4_3', 'intel4_3', 'fun4_3', 'amb4_3', 'shar4_3', 'attr2_3', 'sinc2_3', 'intel2_3', 'fun2_3', 'amb2_3', 'shar2_3', 'attr3_3', 'sinc3_3', 'intel3_3', 'fun3_3', 'amb3_3', 'attr5_3', 'sinc5_3', 'intel5_3', 'fun5_3', 'amb5_3']\n",
            "categorical features: ['gender', 'field', 'undergra', 'mn_sat', 'tuition', 'from', 'career']\n"
          ]
        }
      ],
      "source": [
        "# we extract numeric features and categorical features names\n",
        "# for later use\n",
        "\n",
        "# numeric features can be selected by: (based on the df_train.info() output )\n",
        "features_numeric = list(x_train.select_dtypes(include=['float64', 'int64']))\n",
        "\n",
        "# categorical features can be selected by: (based on the df_train.info() output )\n",
        "features_categorical = list(x_train.select_dtypes(include=['category']))\n",
        "\n",
        "print('numeric features:', features_numeric)\n",
        "print('categorical features:', features_categorical)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3APFHUhE0bTu",
        "outputId": "707dd9cc-ca7c-4808-fdcc-2bbac0014da3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4945e3ed-1385-49db-be93-7caa16e21a01\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>field</th>\n",
              "      <th>undergra</th>\n",
              "      <th>mn_sat</th>\n",
              "      <th>tuition</th>\n",
              "      <th>from</th>\n",
              "      <th>career</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2583</th>\n",
              "      <td>0</td>\n",
              "      <td>Ed.D. in higher education policy at TC</td>\n",
              "      <td>University of Michigan-Ann Arbor</td>\n",
              "      <td>1,290.00</td>\n",
              "      <td>21,645.00</td>\n",
              "      <td>Palo Alto, CA</td>\n",
              "      <td>University President</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6830</th>\n",
              "      <td>1</td>\n",
              "      <td>Engineering</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Boston, MA</td>\n",
              "      <td>Engineer or iBanker or consultant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4840</th>\n",
              "      <td>1</td>\n",
              "      <td>Urban Planning</td>\n",
              "      <td>Rizvi College of Architecture, Bombay University</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Bombay, India</td>\n",
              "      <td>Real Estate Consulting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5508</th>\n",
              "      <td>1</td>\n",
              "      <td>International Affairs</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Washington, DC</td>\n",
              "      <td>public service</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4828</th>\n",
              "      <td>1</td>\n",
              "      <td>Business</td>\n",
              "      <td>Harvard College</td>\n",
              "      <td>1,400.00</td>\n",
              "      <td>26,019.00</td>\n",
              "      <td>Midwest USA</td>\n",
              "      <td>undecided</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3390</th>\n",
              "      <td>0</td>\n",
              "      <td>Clinical Psychology</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>New York</td>\n",
              "      <td>Psychologist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4130</th>\n",
              "      <td>1</td>\n",
              "      <td>MBA</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Colombia</td>\n",
              "      <td>Consulting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1178</th>\n",
              "      <td>0</td>\n",
              "      <td>MA Science Education</td>\n",
              "      <td>University of Washington</td>\n",
              "      <td>1,155.00</td>\n",
              "      <td>13,258.00</td>\n",
              "      <td>Seattle</td>\n",
              "      <td>Teacher</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5016</th>\n",
              "      <td>1</td>\n",
              "      <td>Biochemistry</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Canada</td>\n",
              "      <td>pharmaceuticals and biotechnology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8149</th>\n",
              "      <td>0</td>\n",
              "      <td>MFA Acting Program</td>\n",
              "      <td>Hamilton College</td>\n",
              "      <td>1,280.00</td>\n",
              "      <td>27,350.00</td>\n",
              "      <td>Cambridge, MA</td>\n",
              "      <td>Actress</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5909 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4945e3ed-1385-49db-be93-7caa16e21a01')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4945e3ed-1385-49db-be93-7caa16e21a01 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4945e3ed-1385-49db-be93-7caa16e21a01');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     gender                                   field  \\\n",
              "id                                                    \n",
              "2583      0  Ed.D. in higher education policy at TC   \n",
              "6830      1                             Engineering   \n",
              "4840      1                          Urban Planning   \n",
              "5508      1                   International Affairs   \n",
              "4828      1                                Business   \n",
              "...     ...                                     ...   \n",
              "3390      0                     Clinical Psychology   \n",
              "4130      1                                     MBA   \n",
              "1178      0                    MA Science Education   \n",
              "5016      1                            Biochemistry   \n",
              "8149      0                      MFA Acting Program   \n",
              "\n",
              "                                              undergra    mn_sat    tuition  \\\n",
              "id                                                                            \n",
              "2583                  University of Michigan-Ann Arbor  1,290.00  21,645.00   \n",
              "6830                                               NaN       NaN        NaN   \n",
              "4840  Rizvi College of Architecture, Bombay University       NaN        NaN   \n",
              "5508                                               NaN       NaN        NaN   \n",
              "4828                                   Harvard College  1,400.00  26,019.00   \n",
              "...                                                ...       ...        ...   \n",
              "3390                                               NaN       NaN        NaN   \n",
              "4130                                               NaN       NaN        NaN   \n",
              "1178                          University of Washington  1,155.00  13,258.00   \n",
              "5016                                               NaN       NaN        NaN   \n",
              "8149                                  Hamilton College  1,280.00  27,350.00   \n",
              "\n",
              "                from                             career  \n",
              "id                                                       \n",
              "2583   Palo Alto, CA               University President  \n",
              "6830      Boston, MA  Engineer or iBanker or consultant  \n",
              "4840   Bombay, India             Real Estate Consulting  \n",
              "5508  Washington, DC                     public service  \n",
              "4828     Midwest USA                          undecided  \n",
              "...              ...                                ...  \n",
              "3390        New York                       Psychologist  \n",
              "4130        Colombia                         Consulting  \n",
              "1178         Seattle                            Teacher  \n",
              "5016          Canada  pharmaceuticals and biotechnology  \n",
              "8149   Cambridge, MA                            Actress  \n",
              "\n",
              "[5909 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "# Show all Category in training set \n",
        "x_train.select_dtypes(include=['category'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jAr3FLwxCUTo"
      },
      "outputs": [],
      "source": [
        "# makes the random numbers predictable\n",
        "np.random.seed(0)\n",
        "\n",
        "# define a pipeline for numeric feature preprocessing\n",
        "# we gave them a name so we can set their hyperparameters\n",
        "transformer_numeric = Pipeline(\n",
        "    steps=[\n",
        "        ('imputer', SimpleImputer()),\n",
        "        ('scaler', StandardScaler())]\n",
        ")\n",
        "\n",
        "# define a pipe line for categorical feature preprocessing\n",
        "# we gave them a name so we can set their hyperparameters\n",
        "transformer_categorical = Pipeline(\n",
        "    steps=[\n",
        "        ('imputer', SimpleImputer(strategy='constant')),\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "    ]\n",
        ")\n",
        "# define the preprocessor \n",
        "# we gave them a name so we can set their hyperparameters\n",
        "# we also specify what are the categorical \n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', transformer_numeric, features_numeric),\n",
        "        ('cat', transformer_categorical, features_categorical)\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLOoomHqm82S"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKz00dGZODVc"
      },
      "source": [
        "## **Tuning Methods**\n",
        "\n",
        "Tuning Methods *(Grid Search, Random Search, Bayisen Search)* are available in the scikit-learn class model_selection. It can be initiated by creating an object."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6LHOvU1PWsD"
      },
      "source": [
        "\n",
        "**Parameters of Tuning Methods *(Grid Search, Random Search, Bayisen Search)* method are:**\n",
        "* **estimator:** *(object)* a scikit-learn model.\n",
        "* **param_grid:** *(dict or list of dictionaries)* This enables searching over any sequence of parameter settings.\n",
        "* **scoring:** *(str, callable, list, tuple or dict)* Strategy to evaluate the performance of the cross-validated model on the test set.\n",
        "* **n_jobs:** *(int)* Number of jobs to run in parallel. \n",
        "  * `None` means 1.\n",
        "  * `-1` means using all processors.\n",
        "* **refit:** *(bool, str, or callable)* Refit an estimator using the best found parameters on the whole dataset.\n",
        "* **cv:** *(int, cross-validation generator or an iterable)* determines the cross-validation splitting strategy. Possible inputs for cv are:\n",
        "\n",
        "  * None, to use the default 5-fold cross validation.\n",
        "  * integer, to specify the number of folds in a (Stratified)KFold.\n",
        "  * CV splitter.\n",
        "  * An iterable yielding (train, test) splits as arrays of indices.\n",
        "* **verbose:** *(int)* Controls the verbosity (Controll to show messages)\n",
        "  * `>1`: the computation time for each fold and parameter candidate is displayed.\n",
        "  * `>2` : the score is also displayed.\n",
        "  * `>3` : the fold and candidate parameter indexes are also displayed together with the starting time of the computation.\n",
        "* **error_score:** *(‘raise’ or numeric)* Value to assign to the score if an error occurs in estimator fitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwhabHexNME0"
      },
      "source": [
        "### **Grid Search**\n",
        "\n",
        "Grid search is the process of performing hyperparameter tuning in order to determine the optimal values for a given model. The performance of a model significantly depends on the value of hyperparameters. \n",
        "\n",
        "Grid Search uses a different combination of all the specified hyperparameters and their values and calculates the performance for each combination and selects the best value for the hyperparameters. This makes the processing time-consuming and expensive based on the number of hyperparameters involved."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLRer769joDO"
      },
      "source": [
        "I will create function to create object from Grid Search, fit them and get the best score.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fldkfb8xE_ON"
      },
      "outputs": [],
      "source": [
        "# Make Function to create and fit the Grid Search to pipeline\n",
        "\n",
        "def create_fit_grid_search(full_pipeline, param_grid, cv, X_data, Y_data):\n",
        "  # cv means number of K-fold cross-validation or validation set\n",
        "  # n_jobs means the cucurrent number of jobs (on colab since we only have two cpu cores, we set it to 2)\n",
        "\n",
        "  grid_search = GridSearchCV(\n",
        "      full_pipeline, param_grid, cv=cv, verbose=1, n_jobs=2, \n",
        "      scoring='roc_auc') # create object GridSearchCV\n",
        "\n",
        "  grid_search.fit(X_data, Y_data) # train the gridsearch\n",
        "\n",
        "  print('best score {}'.format(grid_search.best_score_))\n",
        "  print('best score {}'.format(grid_search.best_params_))\n",
        "  return grid_search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vofseo-jZP8"
      },
      "source": [
        "### **Random Search**\n",
        "\n",
        "Random search methods are stochastic approaches that rely entirely on the random sampling of a succession of points in the problem's feasible region, according to a predetermined probability distribution or sequence of probability distributions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPuNlLbxkSL2"
      },
      "source": [
        "I will create function to create object from Random Search, fit them and get the best score.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otoH3B5MV6IY"
      },
      "outputs": [],
      "source": [
        "# Make Function to create and fit the Random Search to pipeline\n",
        "\n",
        "def create_fit_random_search(full_pipeline, param_random, cv, X_data, Y_data):\n",
        "  # cv= cv means cv-fold cross-validation or validation set\n",
        "  # n_jobs means the cucurrent number of jobs\n",
        "  # (on colab since we only have two cpu cores, we set it to 2)\n",
        "  random_search = RandomizedSearchCV(\n",
        "      full_pipeline, param_random, cv=cv, verbose=1, n_jobs=2, \n",
        "      # number of random trials\n",
        "      n_iter=10,\n",
        "      scoring='roc_auc')\n",
        "\n",
        "  random_search.fit(X_data, Y_data)\n",
        "\n",
        "  print('best score {}'.format(random_search.best_score_))\n",
        "  print('best score {}'.format(random_search.best_params_))\n",
        "  return random_search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RkPmmDe4kMyL"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZ16MMwKkV9s"
      },
      "source": [
        "### **Bayesian Search**\n",
        "\n",
        "This model is called a **surrogate** for the objective function. The surrogate is much easier to optimize than the objective function and Bayesian methods work by finding the next set of hyperparameters to evaluate on the actual objective function by selecting hyperparameters that perform best on the surrogate function.\n",
        "\n",
        "Bayesian Search keeps track of previous assessment results, which they use to create a probabilistic model that maps hyperparameters to the likelihood of a score on the objective function.\n",
        "\n",
        "\\\n",
        "This method advocates the usage of intelligence to pick the next set of hyperparameters which will improve the model performance. We iteratively repeat this process until we converge to an optimum.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0L8wCYP-kNO_"
      },
      "source": [
        "I will create function to create object from Bayesian Search, fit them and get the best score.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJ37X1_7oRhL"
      },
      "outputs": [],
      "source": [
        "# Make Function to create and fit the Bayesian Search to pipeline\n",
        "\n",
        "def create_fit_bayesian_search(full_pipeline, param_bayesian, cv, X_data, Y_data):\n",
        "  # cv= cv means cv-fold cross-validation or validation set\n",
        "  # n_jobs means the cucurrent number of jobs\n",
        "  # (on colab since we only have two cpu cores, we set it to 2)\n",
        "  Bayes_search = BayesSearchCV(\n",
        "      full_pipeline, param_bayesian, cv=cv, verbose=1, n_jobs=2, \n",
        "      # number of Bayes trials\n",
        "      n_iter=10,\n",
        "      scoring='roc_auc')\n",
        "\n",
        "  Bayes_search.fit(X_data, Y_data)\n",
        "\n",
        "  print('best score {}'.format(Bayes_search.best_score_))\n",
        "  print('best score {}'.format(Bayes_search.best_params_))\n",
        "  return Bayes_search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5NfnbwGrka-0"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3gFzqF16CF-"
      },
      "source": [
        "## **Different trials on model tuning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXodyQWy64KW"
      },
      "source": [
        "###  **4* XGBoost**\n",
        "\n",
        "\\\n",
        "\n",
        "This algorithm goes by lots of different names such as gradient boosting, multiple additive regression trees, stochastic gradient boosting or gradient boosting machines.\n",
        "\n",
        "A Gradient Boosting Decision Trees (GBDT) is a decision tree ensemble learning algorithm similar to random forest, **Ensemble learning algorithms** combine multiple machine learning algorithms to obtain a better model. **Random forest** uses to build full decision trees in parallel from random bootstrap samples of the data set. \n",
        "\n",
        "It is the top machine learning library for regression, classification, and ranking tasks.\n",
        "\n",
        "* It includes parallel tree boosting.\n",
        "* It supports regularization.\n",
        "* It is designed to handle missing data with its in-build features.\n",
        "* The user can run a cross-validation after each iteration. \n",
        "* It works well in small to medium dataset.\n",
        "* It is designed to be highly efficient, flexible and portable.\n",
        "* It has a distributed weighted quantile sketch algorithm to effectively handle weighted data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdoWL2SZvun6"
      },
      "source": [
        "To develop a model, the XGBoost classifier contains a lot of hyperparameters. I'll use some of them to assist us enhance the model and score.\n",
        "\n",
        "**The hyperparameters are:**\n",
        "* **learning_rate:** Learning rate reduces each tree's contribution by learning rate. Between learning rate and n estimators, there is a trade-off.\n",
        "* **n_estimators:** The number of boosting stages to perform. Gradient boosting is fairly robust to over-fitting so a large number usually results in better performance.\n",
        "* **subsample:** The percentage of samples that will be used to fit particular base learners. Stochastic Gradient Boosting occurs when the value is less than 1.0. The parameter n estimators interacts with subsample. Choosing subsample < 1.0 leads to a reduction of variance and an increase in bias.\n",
        "* **colsample_bytree:** Subsample ratio of columns when constructing each tree.\n",
        "*  **nthread:** Number of threads to use for loading data when parallelization is applicable. If -1, uses maximum threads available on the system.\n",
        "* **objective:** Specify the learning task and the corresponding learning objective or a custom objective function to be used.\n",
        "* **silent:** Whether print messages during construction.\n",
        "* **random_state:** Controls the random seed given to each Tree estimator at each boosting iteration. In addition, it controls the random permutation of the features at each split (see Notes for more details). It also controls the random splitting of the training data to obtain a validation set if n_iter_no_change is not None. Pass an int for reproducible output across multiple function calls.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9U6x0-J0L5r",
        "outputId": "b59190de-020d-4e96-eb7d-abb778832d8b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    2253\n",
              "1     216\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ],
      "source": [
        "# for the create pipeline with my classifier is XGBoost Classifier\n",
        "full_pipeline_XGB = create_fit_pipeline(XGBClassifier(objective='binary:logistic', silent=True, random_state= 42))\n",
        "# prediction the pipeline\n",
        "predict_pipeline(full_pipeline_XGB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oeys8ytp7cwc"
      },
      "source": [
        "#### **1- Grid Search with Validation Set**\n",
        "\n",
        "**using Grid Search and XGBoost Classifier with Validation Set**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXJ_95qxoZNU"
      },
      "source": [
        "**Expectations:**\n",
        "\n",
        "I will use the Grid Search and XGBoost with Validation Set. I expect that it will give me the highest score, because the model try all possible values to know the optimal values, and fit the estimator (model) on your training set.\n",
        "\n",
        "I'm going to specify some hyperparameters for the preprocessor, select features, and XGBoost classifier.\n",
        "\n",
        "\\\n",
        "\n",
        "**observations:**\n",
        "\n",
        "The best hyperparameters for this model will be:\n",
        "* ***objective:** binary:logistic\n",
        "* **silent:** True\n",
        "* **random_state:** 42\n",
        "* **strategy:** mean\n",
        "* **K:** 41\n",
        "* ***learning_rate:** 0.03\n",
        "* **n_estimators:** 1500\n",
        "* **subsample:** 0.9\n",
        "* **colsample_bytree:** 0.8\n",
        "<!-- * **nthread:** --------------------- -->\n",
        "\n",
        "\\\n",
        "\n",
        "\n",
        "Scores:\n",
        "\n",
        "     In colab ==> Score: 0.905785\n",
        "\n",
        "     In Kaggle \n",
        "        * Public score: 0.88052\n",
        "        * Private score: 0.87822\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\\\n",
        "\n",
        "**plan:**\n",
        "\n",
        "I will use Random Search and XGBoost Classifier with Validation Set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PIfeT18HuPZq"
      },
      "outputs": [],
      "source": [
        "# hyperparameter for XGBoost Classifier\n",
        "# here we specify the search space \n",
        "# `__` denotes an attribute of the preceeding name\n",
        "# (e.g. my_classifier__n_estimators means the `n_estimators` param for `my_classifier`)\n",
        "param_grid_XGB = {\n",
        "    'preprocessor__num__imputer__strategy': ['mean'],\n",
        "    # preprocessor__num__imputer__strategy points to preprocessor->num (a Pipeline)-> imputer -> strategy\n",
        "    'selector__k': [41, 50, 60], # for select features\n",
        "     'my_classifier__learning_rate' : [0.01, 0.02, 0.03, 0.1],\n",
        "    'my_classifier__n_estimators' : [1500, 2000, 3000],\n",
        "    # 'my_classifier__min_child_weight': [1, 5, 10],\n",
        "#     'my_classifier__gamma': [0.5, 1, 1.5],\n",
        "    'my_classifier__subsample': [0.6, 0.8, 0.9],\n",
        "    'my_classifier__colsample_bytree': [0.6, 0.7, 0.8],\n",
        "    # 'my_classifier__max_depth': np.arange(1, 20,2)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKKLosix0L5s",
        "outputId": "43a5d84f-b7ae-41aa-fbac-99fb1b1d04c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 1 folds for each of 324 candidates, totalling 324 fits\n",
            "best score 0.9057854972489119\n",
            "best score {'my_classifier__colsample_bytree': 0.8, 'my_classifier__learning_rate': 0.03, 'my_classifier__n_estimators': 1500, 'my_classifier__subsample': 0.9, 'preprocessor__num__imputer__strategy': 'mean', 'selector__k': 41}\n"
          ]
        }
      ],
      "source": [
        "# using the create_fit_grid_search function and it will return grid_search for XGBoost and it will use the (x_train) and (y_train)\n",
        "grid_search_XGB = create_fit_grid_search(full_pipeline_XGB, param_grid_XGB, pds, x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ObGqWV1KwxOY"
      },
      "outputs": [],
      "source": [
        "# using the predict_save_csv function and it will predict the testing data and save it in the csv file\n",
        "predict_save_csv(grid_search_XGB, 'XGB_grid_Validation')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3AuvY7VgzS4a"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbDZd6fQ70ne"
      },
      "source": [
        "#### **2- Random Search with Validation Set**\n",
        "\n",
        "**using Random Search and XGBoost Classifier with Validation Set**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-Gd77e_0H2A"
      },
      "source": [
        "**Expectations:**\n",
        "\n",
        "Random Search and XGBoost with Validation Set will be used. Because Random search works best for lower dimensional data and fits the estimator (model) on your training set, I expect it to give me the greatest score.\n",
        "\n",
        "I'm going to specify some hyperparameters for the preprocessor, select features, and XGBoost classifier.\n",
        "\n",
        "\\\n",
        "\n",
        "**observations:**\n",
        "\n",
        "The best hyperparameters for this model will be:\n",
        "* **objective:** binary:logistic\n",
        "* **silent:** True\n",
        "* **random_state:** 42\n",
        "* **strategy:** mean\n",
        "\n",
        "* **K:** 43\n",
        "* **learning_rate:** 0.02\n",
        "* **n_estimators:** 850\n",
        "* **subsample:** 0.6\n",
        "* **gamma:** 1\n",
        "* **nthread:** 5\n",
        "\n",
        "\\\n",
        "Scores:\n",
        "\n",
        "     In colab ==> Score: 0.88398\n",
        "\n",
        "     In Kaggle \n",
        "        * Public score:  0.87908\n",
        "        * Private score: 0.87673\n",
        "\n",
        "\n",
        "\\\n",
        "\n",
        "**plan:**\n",
        "\n",
        "I will use Bayesian Search and XGBoost Classifier with Cross Validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7L5MerY4zdu4"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_dpKMqpx0L5t"
      },
      "outputs": [],
      "source": [
        "# hyperparameter for XGBoost Classifier\n",
        "# here we specify the search space \n",
        "# `__` denotes an attribute of the preceeding name\n",
        "# (e.g. my_classifier__n_estimators means the `n_estimators` param for `my_classifier`)\n",
        "param_XGB = {\n",
        "    'preprocessor__num__imputer__strategy': ['mean'],\n",
        "    # preprocessor__num__imputer__strategy points to preprocessor->num (a Pipeline)-> imputer -> strategy\n",
        "    'selector__k': [20, 30, 35, 40, 41, 42, 43, 55], \n",
        "#     'my_classifier__random_state' : [0, 1, 42, 15],\n",
        "    'my_classifier__learning_rate' : [0.01,0.02, 0.05, 0.1],\n",
        "    'my_classifier__n_estimators' : [400, 600, 700, 800, 850],\n",
        "    'my_classifier__nthread' : [1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
        "#     'my_classifier__min_child_weight': [1, 5, 10],\n",
        "    'my_classifier__gamma': [0.4, 0.5, 0.6, 1, 1.5, 2, 2.5, 3, 5],\n",
        "    'my_classifier__subsample': [0.6, 0.8, 0.9, 1.0],\n",
        "#     'my_classifier__colsample_bytree': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
        "#     'my_classifier__max_depth': np.arange(3, 20, 2)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMU3CCbK09PR",
        "outputId": "18f73787-ebcf-4615-eea0-d33f62052557"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 20 folds for each of 10 candidates, totalling 200 fits\n",
            "best score 0.8839801366186842\n",
            "best score {'selector__k': 42, 'preprocessor__num__imputer__strategy': 'mean', 'my_classifier__subsample': 0.9, 'my_classifier__nthread': 1, 'my_classifier__n_estimators': 700, 'my_classifier__learning_rate': 0.05, 'my_classifier__gamma': 1}\n",
            "Best: 0.883980 using {'selector__k': 42, 'preprocessor__num__imputer__strategy': 'mean', 'my_classifier__subsample': 0.9, 'my_classifier__nthread': 1, 'my_classifier__n_estimators': 700, 'my_classifier__learning_rate': 0.05, 'my_classifier__gamma': 1}\n"
          ]
        }
      ],
      "source": [
        "# using the create_fit_Random_search function and it will return Random_search for XGBoost and it will use the (x_train) and (y_train)\n",
        "random_search_XGB = create_fit_random_search(full_pipeline_XGB, param_XGB, 20, x_train, y_train)\n",
        "print(\"Best: %f using %s\" % (random_search_XGB.best_score_, random_search_XGB.best_params_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5Jpi-mJ5lav"
      },
      "outputs": [],
      "source": [
        "# using the predict_save_csv function and it will predict the testing data and save it in the csv file\n",
        "predict_save_csv(random_search_XGB, 'XGB_Random_Validation')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVD3Rbxc5ykP"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAz1EOD25yu-"
      },
      "source": [
        "#### **3- Bayesian Search with Cross Validation**\n",
        "\n",
        "**using Bayesian Search and XGBoost Classifier with Cross Validation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqsZpTft-vb9"
      },
      "source": [
        "**Expectations:**\n",
        "\n",
        "I'll utilise Cross Validation with Bayesian Search and XGBoost. Because Bayesian Search discovers the extrema of objective functions that are expensive to evaluate and fits the estimator (model) on your training set, I expect it to give me the greatest score.\n",
        "\n",
        "I'm going to specify some hyperparameters for the preprocessor, select features, and XGBoost classifier.\n",
        "\n",
        "\\\n",
        "\n",
        "**observations:**\n",
        "\n",
        "The best hyperparameters for this model will be:\n",
        "* **objective:** binary:logistic\n",
        "* **silent:** True\n",
        "* **random_state:** 42\n",
        "* **strategy:** mean\n",
        "* **K:** 120\n",
        "* **learning_rate:** 0.01\n",
        "* **n_estimators:** 3000\n",
        "* **subsample:** 0.8\n",
        "* **colsample_bytree:** 0.8\n",
        "* **nthread:** 6\n",
        "* **CV:** 20\n",
        "\n",
        "\\\n",
        "\n",
        "\n",
        "Scores:\n",
        "\n",
        "     In colab ==> Score: 0.888194\n",
        "\n",
        "     In Kaggle \n",
        "        * Public score: 0.88872\n",
        "        * Private score: 0.89038\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\\\n",
        "\n",
        "**plan:**\n",
        "\n",
        "I will use Bayesian Search and XGBoost Classifier with Validation Set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgfgTwP--Km8"
      },
      "outputs": [],
      "source": [
        "# hyperparameter for XGBoost Classifier\n",
        "# here we specify the search space \n",
        "# `__` denotes an attribute of the preceeding name\n",
        "# (e.g. my_classifier__n_estimators means the `n_estimators` param for `my_classifier`)\n",
        "param_XGB = {\n",
        "    'preprocessor__num__imputer__strategy': ['mean'],\n",
        "    # preprocessor__num__imputer__strategy points to preprocessor->num (a Pipeline)-> imputer -> strategy\n",
        "    'selector__k': [40, 41, 42, 43, 55, 70, 90, 100, 120, 130], \n",
        "    'my_classifier__learning_rate' : [0.005, 0.001, 0.01, 0.02, 0.03, 0.05, 0.1, 0.2, 0.3],\n",
        "    'my_classifier__n_estimators' : [600,1000, 1100, 1500, 2000, 3000, 4000],\n",
        "    'my_classifier__nthread' : [1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
        "#     'my_classifier__min_child_weight': [1, 5, 10],\n",
        "#     'my_classifier__gamma': [0.4, 0.5, 0.6, 1, 1.5, 2, 2.5, 3, 5],\n",
        "    'my_classifier__subsample': [0.05, 0.2, 0.3, 0.6, 0.8, 0.9],\n",
        "    'my_classifier__colsample_bytree': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
        "#     'my_classifier__max_depth': np.arange(3, 20),\n",
        "#     'my_classifier__random_state' : [0, 1, 42, 15]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OEmIeP1AwlXN",
        "outputId": "1f66f4fc-bf88-412b-f52d-6bf3b9023033"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 20 folds for each of 1 candidates, totalling 20 fits\n",
            "Fitting 20 folds for each of 1 candidates, totalling 20 fits\n",
            "Fitting 20 folds for each of 1 candidates, totalling 20 fits\n",
            "Fitting 20 folds for each of 1 candidates, totalling 20 fits\n",
            "Fitting 20 folds for each of 1 candidates, totalling 20 fits\n",
            "Fitting 20 folds for each of 1 candidates, totalling 20 fits\n",
            "Fitting 20 folds for each of 1 candidates, totalling 20 fits\n",
            "Fitting 20 folds for each of 1 candidates, totalling 20 fits\n",
            "Fitting 20 folds for each of 1 candidates, totalling 20 fits\n",
            "Fitting 20 folds for each of 1 candidates, totalling 20 fits\n",
            "[23:48:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
            "Parameters: { \"silent\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[23:48:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "best score 0.8881941805062106\n",
            "best score OrderedDict([('my_classifier__colsample_bytree', 0.8), ('my_classifier__learning_rate', 0.01), ('my_classifier__n_estimators', 3000), ('my_classifier__nthread', 6), ('my_classifier__subsample', 0.8), ('preprocessor__num__imputer__strategy', 'mean'), ('selector__k', 120)])\n",
            "Best: 0.888194 using OrderedDict([('my_classifier__colsample_bytree', 0.8), ('my_classifier__learning_rate', 0.01), ('my_classifier__n_estimators', 3000), ('my_classifier__nthread', 6), ('my_classifier__subsample', 0.8), ('preprocessor__num__imputer__strategy', 'mean'), ('selector__k', 120)])\n"
          ]
        }
      ],
      "source": [
        "# using the create_fit_bayesian_search function and it will return bayesian_search for XGBoost and it will use the (x_train) and (y_train)\n",
        "grid_search_XGB = create_fit_bayesian_search(full_pipeline_XGB, param_grid_XGB, 20, x_train, y_train)\n",
        "print(\"Best: %f using %s\" % (grid_search_XGB.best_score_, grid_search_XGB.best_params_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "500XUc90-Mc1"
      },
      "outputs": [],
      "source": [
        "# using the predict_save_csv function and it will predict the testing data and save it in the csv file\n",
        "predict_save_csv(grid_search_XGB, 'XGB_Bayesian_Cross')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvL-bSOzORKe"
      },
      "source": [
        "#### **4- Bayesian Search with Validation Set**\n",
        "\n",
        "**using Bayesian Search and XGBoost Classifier with Validation Set**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZQfAWGwOix_"
      },
      "source": [
        "**Expectations:**\n",
        "\n",
        "I'll utilise Validation Set with Bayesian Search and XGBoost. Because Bayesian Search discovers the extrema of objective functions that are expensive to evaluate and fits the estimator (model) on your training set, I expect it to give me the greatest score.\n",
        "\n",
        "I'm going to specify some hyperparameters for the preprocessor, select features, and XGBoost classifier.\n",
        "\n",
        "\\\n",
        "\n",
        "**observations:**\n",
        "\n",
        "The best hyperparameters for this model will be:\n",
        "* **objective:** binary:logistic\n",
        "* **silent:** True\n",
        "* **random_state:** 42\n",
        "* **strategy:** mean\n",
        "* **K:** 41\n",
        "* **learning_rate:** 0.01\n",
        "* **n_estimators:** 3000\n",
        "* **subsample:** 0.8\n",
        "* **colsample_bytree:** 0.7\n",
        "* **CV:** 60\n",
        "\n",
        "\\\n",
        "\n",
        "\n",
        "Scores:\n",
        "\n",
        "     In colab ==> Score: 0.90328\n",
        "\n",
        "     In Kaggle \n",
        "        * Public score:  0.88325\n",
        "        * Private score: 0.88308\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\\\n",
        "\n",
        "**plan:**\n",
        "\n",
        "I will use Random Search and Logistic Regression Classifier with Cross Validation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDWPOM6EOiyA",
        "outputId": "d9651ec3-93d0-44d0-d87c-60b6df121536"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "best score 0.9032807752319947\n",
            "best score OrderedDict([('my_classifier__colsample_bytree', 0.7), ('my_classifier__learning_rate', 0.02), ('my_classifier__n_estimators', 3000), ('my_classifier__subsample', 0.6), ('preprocessor__num__imputer__strategy', 'mean'), ('selector__k', 41)])\n"
          ]
        }
      ],
      "source": [
        "# using the create_fit_bayesian_search function and it will return bayesian_search for XGBoost and it will use the (x_train) and (y_train)\n",
        "grid_search_XGB = create_fit_bayesian_search(full_pipeline_XGB, param_grid_XGB, pds, x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UwIy6bnMOiyA"
      },
      "outputs": [],
      "source": [
        "# using the predict_save_csv function and it will predict the testing data and save it in the csv file\n",
        "predict_save_csv(grid_search_XGB, 'XGB_Bayesian_Validation')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlUxGH47iBO-"
      },
      "source": [
        "### **2* Logistic Regression**\n",
        "\n",
        "Logistic regression is used to handle the classification problems.\n",
        "\n",
        "It is used in statistical software to understand the relationship between the dependent variable and one or more independent variables by estimating probabilities using a logistic regression equation.  \n",
        "\n",
        "It is often used for predictive analytics and modeling, and extends to applications in machine learning. Logistic regression is easier to implement, interpret, and very efficient to train. \n",
        "\n",
        "\\\n",
        "\n",
        "**There are three main types of logistic regression:**\n",
        " * **Binary regression** deals with two possible values, essentially: yes or no. \n",
        " * **Multinomial logistic regression** deals with three or more values.\n",
        " * **ordinal logistic regression** deals with three or more classes in a predetermined order. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHPiV1_7nSEO"
      },
      "source": [
        "To develop a model, the Logistic Regression classifier contains a lot of hyperparameters. I'll use some of them to assist us enhance the model and score.\n",
        "\n",
        "**The hyperparameters are:**\n",
        "* **penalty:** Used to specify the norm used in the penalization. The newton-cg and lbfgs solvers support only l2 penalties.\n",
        "   * `'none':` no penalty is added;\n",
        "   * `'l2':` add a L2 penalty term and it is the default choice;\n",
        "   * `'l1':` add a L1 penalty term;\n",
        "   * `'elasticnet':` both L1 and L2 penalty terms are added.\n",
        "\n",
        "* **C:** Inverse of regularization strength.\n",
        "* **solver:** *(‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’)* use in the optimization problem. Default is ‘lbfgs’.\n",
        "  * `For small datasets, ‘liblinear’` is a good choice, whereas ‘sag’ and ‘saga’ are faster for large ones;\n",
        "  * `For multiclass problems,` only ‘newton-cg’, ‘sag’, ‘saga’ and ‘lbfgs’ handle multinomial loss;\n",
        "  * `‘liblinear’` is limited to one-versus-rest schemes.\n",
        "* **random_state:** Used when solver == ‘sag’, ‘saga’ or ‘liblinear’ to shuffle the data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B7Hu-63irD2A"
      },
      "outputs": [],
      "source": [
        "# for the create pipeline with my classifier is Logistic Regression Classifier\n",
        "full_pipeline_Log = create_fit_pipeline(LogisticRegression(random_state = 42))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnyi1nIDsoWg"
      },
      "outputs": [],
      "source": [
        "# hyperparameter for Logistic Regression Classifier\n",
        "# here we specify the search space \n",
        "# `__` denotes an attribute of the preceeding name\n",
        "# (e.g. my_classifier__n_estimators means the `n_estimators` param for `my_classifier`)\n",
        "param_Log = {\n",
        "    'preprocessor__num__imputer__strategy': ['mean'],\n",
        "    # preprocessor__num__imputer__strategy points to preprocessor->num (a Pipeline)-> imputer -> strategy\n",
        "    'selector__k': [40, 41, 42, 43, 55, 70, 90, 100, 120, 130],\n",
        "#     'my_classifier__random_state' : [0, 1, 42, 15, 2],\n",
        "    'my_classifier__penalty' : ['l1', 'l2', 'elasticnet'],\n",
        "    'my_classifier__C' : [0.001,0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.1, 1],\n",
        "    'my_classifier__solver' : ['newton-cg', 'sag', 'saga', 'lbfgs']\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a98ajnD7idLs"
      },
      "source": [
        "#### **1- Random Search With Cross Validation**\n",
        "\n",
        "**using Random Search and Logistic Regression Classifier with Cross Validation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKC3NgMeidLt"
      },
      "source": [
        "**Expectations:**\n",
        "\n",
        "Random Search and Logistic Regression with Cross Validation will be used. Because Random search works best for lower dimensional data and fits the estimator (model) on your training set, I expect it to give me the greatest score.\n",
        "\n",
        "I'm going to specify some hyperparameters for the preprocessor, select features, and Logistic Regression classifier.\n",
        "\n",
        "\\\n",
        "\n",
        "**observations:**\n",
        "\n",
        "The best hyperparameters for this model will be:\n",
        "* **random_state:** 42\n",
        "* **strategy:** mean\n",
        "\n",
        "* **K:** 120\n",
        "* **penalty:** l2\n",
        "* **C:** 0.04\n",
        "* **solver:** lbfgs\n",
        "\n",
        "\n",
        "\\\n",
        "Scores:\n",
        "\n",
        "     In colab ==> Score: 0.8590\n",
        "\n",
        "     In Kaggle \n",
        "        * Public score: 0.86515\n",
        "        * Private score: 0.85417\n",
        "\n",
        "\n",
        "\\\n",
        "\n",
        "**plan:**\n",
        "\n",
        "I will use Bayesian Search and Logistic Regressio Classifier with Cross Validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPf8torZrakg",
        "outputId": "27c8f544-6bc3-4ed5-df9f-0f6f5224a78d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 20 folds for each of 10 candidates, totalling 200 fits\n",
            "best score 0.8590295841453003\n",
            "best score {'selector__k': 120, 'preprocessor__num__imputer__strategy': 'mean', 'my_classifier__solver': 'lbfgs', 'my_classifier__penalty': 'l2', 'my_classifier__C': 0.04}\n"
          ]
        }
      ],
      "source": [
        "# using the create_fit_grid_search function and it will return grid_search for Logistic Regression and it will use the (x_train) and (y_train)\n",
        "random_search_Log = create_fit_random_search(full_pipeline_Log, param_Log, 20, x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJVSsFAcidLt"
      },
      "outputs": [],
      "source": [
        "# using the predict_save_csv function and it will predict the testing data and save it in the csv file\n",
        "predict_save_csv(random_search_Log, 'Log_Random_Cross')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FG1V1-PXtJ2f"
      },
      "source": [
        "#### **2- Bayesian Search With Cross Validation**\n",
        "\n",
        "**using Bayesian Search and Logistic Regression Classifier with Cross Validation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMIc0Pm3tJ2f"
      },
      "source": [
        "**Expectations:**\n",
        "\n",
        "Bayesian Search and Logistic Regression with Cross Validation will be used. Because Bayesian Search discovers the extrema of objective functions that are expensive to evaluate and fits the estimator (model) on your training set, I expect it to give me the greatest score.\n",
        "\n",
        "I'm going to specify some hyperparameters for the preprocessor, select features, and Logistic Regression classifier.\n",
        "\n",
        "\\\n",
        "\n",
        "**observations:**\n",
        "\n",
        "The best hyperparameters for this model will be:\n",
        "* **random_state:** 42\n",
        "* **strategy:** mean\n",
        "\n",
        "* **K:** 55\n",
        "* **penalty:** none\n",
        "* **C:** 0.02\n",
        "* **solver:** sag\n",
        "\n",
        "\n",
        "\\\n",
        "Scores:\n",
        "\n",
        "     In colab ==> Score: 0.85860\n",
        "\n",
        "     In Kaggle \n",
        "        * Public score: 0.86203\n",
        "        * Private score: 0.84995\n",
        "\n",
        "\n",
        "\\\n",
        "\n",
        "**plan:**\n",
        "\n",
        "I will use Grid Search and SVM Classifier with Cross Validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALV-0zK91q3e"
      },
      "outputs": [],
      "source": [
        "# hyperparameter for Logistic Regression Classifier\n",
        "# here we specify the search space \n",
        "# `__` denotes an attribute of the preceeding name\n",
        "# (e.g. my_classifier__n_estimators means the `n_estimators` param for `my_classifier`)\n",
        "param_Log = {\n",
        "    'preprocessor__num__imputer__strategy': ['mean'],\n",
        "    # preprocessor__num__imputer__strategy points to preprocessor->num (a Pipeline)-> imputer -> strategy\n",
        "    'selector__k': [40, 41, 42, 43, 55, 70, 90, 100, 120, 130],\n",
        "#     'my_classifier__random_state' : [0, 1, 42, 15, 2],\n",
        "    'my_classifier__penalty' : ['l2', 'none'],\n",
        "    'my_classifier__C' : [0.001,0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.1, 1],\n",
        "    'my_classifier__solver' : ['newton-cg', 'sag', 'saga', 'lbfgs']\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pqy25LoNtJ2f",
        "outputId": "d410cc15-404b-49c9-9a9c-de47c67ca558"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 20 folds for each of 1 candidates, totalling 20 fits\n",
            "Fitting 20 folds for each of 1 candidates, totalling 20 fits\n",
            "Fitting 20 folds for each of 1 candidates, totalling 20 fits\n",
            "Fitting 20 folds for each of 1 candidates, totalling 20 fits\n",
            "Fitting 20 folds for each of 1 candidates, totalling 20 fits\n",
            "Fitting 20 folds for each of 1 candidates, totalling 20 fits\n",
            "Fitting 20 folds for each of 1 candidates, totalling 20 fits\n",
            "Fitting 20 folds for each of 1 candidates, totalling 20 fits\n",
            "Fitting 20 folds for each of 1 candidates, totalling 20 fits\n",
            "Fitting 20 folds for each of 1 candidates, totalling 20 fits\n",
            "best score 0.8586056091045087\n",
            "best score OrderedDict([('my_classifier__C', 0.02), ('my_classifier__penalty', 'none'), ('my_classifier__solver', 'sag'), ('preprocessor__num__imputer__strategy', 'mean'), ('selector__k', 55)])\n"
          ]
        }
      ],
      "source": [
        "# using the create_fit_grid_search function and it will return grid_search for Logistic Regression and it will use the (x_train) and (y_train)\n",
        "bayesian_search_Log = create_fit_bayesian_search(full_pipeline_Log, param_Log, 20, x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47ySpglMtJ2f"
      },
      "outputs": [],
      "source": [
        "# using the predict_save_csv function and it will predict the testing data and save it in the csv file\n",
        "predict_save_csv(bayesian_search_Log, 'Log_Bayesian_Cross')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HepNReZg9-qD"
      },
      "source": [
        "### **2* SVM**\n",
        "\n",
        "The objective of the support vector machine algorithm is to find a hyperplane in an N-dimensional space(N — the number of features) that distinctly classifies the data points.\n",
        "\n",
        "It uses classification algorithms for two-group classification problems. After giving an SVM model sets of labeled training data for each category, they’re able to categorize new text.\n",
        "\n",
        "\\\n",
        "It is higher speed and better performance with a limited number of samples (in the thousands). This makes the algorithm very suitable for text classification problems, where it’s common to have access to a dataset of at most a couple of thousands of tagged samples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dwladLavjhB"
      },
      "source": [
        "To develop a model, the SVM classifier contains a lot of hyperparameters. I'll use some of them to assist us enhance the model and score.\n",
        "\n",
        "**The hyperparameters are:**\n",
        "* **C:** Regularization parameter. The strength of the regularization is inversely proportional to C. Must be strictly positive. The penalty is a squared l2 penalty.\n",
        "* **kernel:** *(‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’)* Specifies the kernel type to be used in the algorithm. If none is given, ‘rbf’ will be used. If a callable is given it is used to pre-compute the kernel matrix from data matrices.\n",
        "* **gamma:** *(‘scale’, ‘auto’)* \n",
        " * if `gamma='scale'` (default) is passed then it uses 1 / (n_features * X.var()) as value of gamma,\n",
        " * if `‘auto’`, uses 1 / n_features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abV1KiMQxZ1S"
      },
      "outputs": [],
      "source": [
        "# for the create pipeline with my classifier is SVM Classifier\n",
        "full_pipeline_SVM = create_fit_pipeline(SVC(probability= True, random_state = 42))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2c1n4YY0xotq"
      },
      "outputs": [],
      "source": [
        "# hyperparameter for SVM Classifier\n",
        "# here we specify the search space \n",
        "# `__` denotes an attribute of the preceeding name\n",
        "# (e.g. my_classifier__n_estimators means the `n_estimators` param for `my_classifier`)\n",
        "param_SVM = {\n",
        "    'preprocessor__num__imputer__strategy': ['mean'],\n",
        "    # preprocessor__num__imputer__strategy points to preprocessor->num (a Pipeline)-> imputer -> strategy\n",
        "    'selector__k': [20, 30, 35, 60,  100, 130],\n",
        "    'my_classifier__C': [0.1, 0.01, 1],\n",
        "    'my_classifier__gamma': [\"auto\", \"scale\"],\n",
        "    'my_classifier__kernel': ['rbf']\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeHLhA0_QMcO"
      },
      "source": [
        "#### **1- Grid Search With Cross Validation**\n",
        "\n",
        "**using Grid Search and SVM Classifier with Cross Validation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioZups_8Q2T4"
      },
      "source": [
        "**Expectations:**\n",
        "\n",
        "Grid Search and SVM with Cross Validation will be used. I expect that it will give me the highest score, because the model try all possible values to know the optimal values, and fit the estimator (model) on your training set.\n",
        "\n",
        "I'm going to specify some hyperparameters for the preprocessor, select features, and XGBoost classifier.\n",
        "\n",
        "\\\n",
        "\n",
        "**observations:**\n",
        "\n",
        "The best hyperparameters for this model will be:\n",
        "* **random_state:** 42\n",
        "* **strategy:** mean\n",
        "\n",
        "* **K:** 100\n",
        "* **C:** 0.01\n",
        "* **gamma:** scale\n",
        "* **kernel:** rbf\n",
        "\n",
        "\\\n",
        "Scores:\n",
        "\n",
        "     In colab ==> Score: 0.85665\n",
        "\n",
        "     In Kaggle \n",
        "        * Public score: 0.86524\n",
        "        * Private score: 0.86463\n",
        "\n",
        "\n",
        "\\\n",
        "\n",
        "**plan:**\n",
        "\n",
        "I will use Bayesian Search and SVM Classifier with Validation Set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSmr7B3bQLsA",
        "outputId": "cecdbef3-cd5d-435b-b1cf-bd3d71110bf6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 20 folds for each of 1 candidates, totalling 20 fits\n",
            "Fitting 20 folds for each of 1 candidates, totalling 20 fits\n",
            "Fitting 20 folds for each of 1 candidates, totalling 20 fits\n",
            "Fitting 20 folds for each of 1 candidates, totalling 20 fits\n",
            "Fitting 20 folds for each of 1 candidates, totalling 20 fits\n",
            "Fitting 20 folds for each of 1 candidates, totalling 20 fits\n",
            "Fitting 20 folds for each of 1 candidates, totalling 20 fits\n",
            "Fitting 20 folds for each of 1 candidates, totalling 20 fits\n",
            "Fitting 20 folds for each of 1 candidates, totalling 20 fits\n",
            "Fitting 20 folds for each of 1 candidates, totalling 20 fits\n",
            "best score 0.8566532446097824\n",
            "best score OrderedDict([('my_classifier__C', 0.01), ('my_classifier__gamma', 'scale'), ('my_classifier__kernel', 'rbf'), ('preprocessor__num__imputer__strategy', 'mean'), ('selector__k', 100)])\n"
          ]
        }
      ],
      "source": [
        "# using the create_fit_grid_search function and it will return grid_search for SVM and it will use the (x_train) and (y_train)\n",
        "grid_search_SVM = create_fit_bayesian_search(full_pipeline_SVM, param_SVM, 20, x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjEJSAd-yAvC"
      },
      "outputs": [],
      "source": [
        "# using the predict_save_csv function and it will predict the testing data and save it in the csv file\n",
        "predict_save_csv(grid_search_SVM, 'SVM_Grid_Cross')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yjXDmqryRMf"
      },
      "source": [
        "#### **2- Bayesian Search With Validation Set**\n",
        "\n",
        "**using Bayesian Search and SVM Classifier with Validation Set**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_HpyXAZyRMf"
      },
      "source": [
        "**Expectations:**\n",
        "\n",
        "Bayesian Search and SVM with Validation Set will be used. Because Bayesian Search discovers the extrema of objective functions that are expensive to evaluate and fits the estimator (model) on your training set, I expect it to give me the greatest score.\n",
        "\n",
        "I'm going to specify some hyperparameters for the preprocessor, select features, and XGBoost classifier.\n",
        "\n",
        "\\\n",
        "\n",
        "**observations:**\n",
        "\n",
        "The best hyperparameters for this model will be:\n",
        "* **random_state:** 42\n",
        "* **strategy:** mean\n",
        "\n",
        "* **K:** 130\n",
        "* **C:** 0.1\n",
        "* **gamma:** scale\n",
        "* **kernel:** rbf\n",
        "\n",
        "\\\n",
        "Scores:\n",
        "\n",
        "     In colab ==> Score: 0.87478\n",
        "\n",
        "     In Kaggle \n",
        "        * Public score: 0.85677\n",
        "        * Private score: 0.86006\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OKLiAI7UyRMg",
        "outputId": "cb405bd4-47f3-419b-a52f-f10841e03130"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "best score 0.8747895622895623\n",
            "best score OrderedDict([('my_classifier__C', 0.1), ('my_classifier__gamma', 'scale'), ('my_classifier__kernel', 'rbf'), ('preprocessor__num__imputer__strategy', 'mean'), ('selector__k', 130)])\n"
          ]
        }
      ],
      "source": [
        "# using the create_fit_bayesian_search function and it will return bayesian_search for SVM and it will use the (x_train) and (y_train)\n",
        "bayesian_search_SVM = create_fit_bayesian_search(full_pipeline_SVM, param_SVM, pds, x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzPoZPuiyRMg"
      },
      "outputs": [],
      "source": [
        "# using the predict_save_csv function and it will predict the testing data and save it in the csv file\n",
        "predict_save_csv(bayesian_search_SVM, 'SVM_Bayesian_Validation')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASHYQGeUg5at"
      },
      "source": [
        "# Reference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3ScvM1XhRkl"
      },
      "source": [
        "https://www.nvidia.com/en-us/glossary/data-science/xgboost/#:~:text=XGBoost%2C%20which%20stands%20for%20Extreme,%2C%20classification%2C%20and%20ranking%20problems.\n",
        "\n",
        "\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\n",
        " \n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
        "\n",
        "\n",
        "https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f\n",
        "\n",
        "\n",
        "https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [
        "GSZRM15PNRMI",
        "0VhHuObDLnsE",
        "M1FDf-taLwws",
        "7wBLUiHhL00D",
        "KfCzc5IBL41M",
        "aj3_r7c2L8Qy",
        "O9e_kyFjMAKD",
        "VTW_FVARqBRD",
        "_ktcYEuvrsOj",
        "kAApGZ3TNfBJ",
        "pn0twbaGKppZ",
        "5GSnNbXL4u4y",
        "U_UQW3rwSPZ9",
        "QiDqqaiSUHl0",
        "FABO1ogiB_aw",
        "iKz00dGZODVc",
        "PwhabHexNME0",
        "0vofseo-jZP8",
        "mZ16MMwKkV9s",
        "Oeys8ytp7cwc",
        "GlUxGH47iBO-",
        "a98ajnD7idLs",
        "FG1V1-PXtJ2f",
        "HepNReZg9-qD",
        "JeHLhA0_QMcO",
        "3yjXDmqryRMf",
        "ASHYQGeUg5at"
      ],
      "name": "DM_Compition_2_With_Doc_1_Final.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}